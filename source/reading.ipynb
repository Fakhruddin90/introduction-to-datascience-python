{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99709a88",
   "metadata": {},
   "source": [
    "(reading)=\n",
    "# Reading in data locally and from the web\n",
    "\n",
    "We need to import the `pandas` package in order to read data into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c438db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfee6750",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a125d",
   "metadata": {},
   "source": [
    "## Overview \n",
    "\n",
    "```{index} see: loading; reading\n",
    "```\n",
    "\n",
    "```{index} reading; definition\n",
    "```\n",
    "\n",
    "In this chapter, you’ll learn to read tabular data of various formats into Python\n",
    "from your local device (e.g., your laptop) and the web. “Reading” (or “loading”)\n",
    "is the process of\n",
    "converting data (stored as plain text, a database, HTML, etc.) into an object\n",
    "(e.g., a data frame) that Python can easily access and manipulate. Thus reading data\n",
    "is the gateway to any data analysis; you won’t be able to analyze data unless\n",
    "you’ve loaded it first. And because there are many ways to store data, there\n",
    "are similarly many ways to read data into Python. The more time you spend upfront\n",
    "matching the data reading method to the type of data you have, the less time\n",
    "you will have to devote to re-formatting, cleaning and wrangling your data (the\n",
    "second step to all data analyses). It’s like making sure your shoelaces are\n",
    "tied well before going for a run so that you don’t trip later on!\n",
    "\n",
    "## Chapter learning objectives\n",
    "By the end of the chapter, readers will be able to do the following:\n",
    "\n",
    "- Define the following:\n",
    "    - absolute file path\n",
    "    - relative file path\n",
    "    - **U**niform **R**esource **L**ocator (URL)\n",
    "- Read data into Python using an absolute path, relative path and a URL.\n",
    "- Compare and contrast the following functions:\n",
    "    - `read_csv` \n",
    "    - `read_table`\n",
    "    - `read_excel`\n",
    "- Match the following `pandas` `.read_*` function arguments to their descriptions:\n",
    "    - `filepath_or_buffer` \n",
    "    - `sep`\n",
    "    - `names`\n",
    "    - `skiprows`\n",
    "\n",
    "- Choose the appropriate `pandas` `.read_*` function and function arguments to load a given plain text tabular data set into Python.\n",
    "- Use `pandas` package's `read_excel` function and arguments to load a sheet from an excel file into Python.\n",
    "- Connect to a database using the `SQLAlchemy` library.\n",
    "- List the tables in a database using `SQLAlchemy` library's `table_names` function\n",
    "- Create a reference to a database table that is queriable using the `SQLAlchemy` library's `select` \n",
    "and `where` functions\n",
    "- Use `.to_csv` to save a data frame to a csv file\n",
    "- (*Optional*) Obtain data using **a**pplication **p**rogramming **i**nterfaces (APIs) and web scraping.\n",
    "    - Read/scrape data from an internet URL using the `BeautifulSoup` package\n",
    "    - Compare downloading tabular data from a plain text file (e.g. *.csv) from the web versus scraping data from a .html file\n",
    "\n",
    "## Absolute and relative file paths\n",
    "\n",
    "```{index} see: location; path\n",
    "```\n",
    "\n",
    "```{index} path; local, path; remote, path; relative, path; absolute\n",
    "```\n",
    "\n",
    "This chapter will discuss the different functions we can use to import data\n",
    "into Python, but before we can talk about *how* we read the data into Python with these\n",
    "functions, we first need to talk about *where* the data lives. When you load a\n",
    "data set into Python, you first need to tell Python where those files live. The file\n",
    "could live on your  computer (*local*) \n",
    "or somewhere on the internet (*remote*). \n",
    "\n",
    "The place where the file lives on your computer is called the \"path\". You can\n",
    "think of the path as directions to the file. There are two kinds of paths:\n",
    "*relative* paths and *absolute* paths. A relative path is where the file is\n",
    "with respect to where you currently are on the computer (e.g., where the file\n",
    "you're working in is). On the other hand, an absolute path is where the file is\n",
    "in respect to the computer's filesystem base (or root) folder.\n",
    "\n",
    "```{index} Happiness Report\n",
    "```\n",
    "\n",
    "Suppose our computer's filesystem looks like the picture in\n",
    "{numref}`Filesystem`, and we are working in a\n",
    "file titled `worksheet_02.ipynb`. If we want to \n",
    "read the `.csv` file named `happiness_report.csv` into Python, we could do this\n",
    "using either a relative or an absolute path.  We show both choices\n",
    "below.\n",
    "\n",
    "```{figure} img/filesystem.jpeg\n",
    "---\n",
    "height: 400px\n",
    "name: Filesystem\n",
    "---\n",
    "Example file system\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Reading `happiness_report.csv` using a relative path:**\n",
    "\n",
    "```{code-cell eval=False} ipython3\n",
    "happy_data = pd.read_csv(\"data/happiness_report.csv\")\n",
    "```\n",
    "\n",
    "**Reading `happiness_report.csv` using an absolute path:**\n",
    "\n",
    "```{code-cell eval=False} ipython3\n",
    "happy_data = pd.read_csv(\"/home/dsci-100/worksheet_02/data/happiness_report.csv\")\n",
    "```\n",
    "\n",
    "So which one should you use? Generally speaking, to ensure your code can be run \n",
    "on a different computer, you should use relative paths. An added bonus is that \n",
    "it's also less typing! Generally, you should use relative paths because the file's \n",
    "absolute path (the names of \n",
    "folders between the computer's root `/` and the file) isn't usually the same \n",
    "across different computers. For example, suppose Fatima and Jayden are working on a \n",
    "project together on the `happiness_report.csv` data. Fatima's file is stored at \n",
    "\n",
    "`/home/Fatima/project/data/happiness_report.csv`, \n",
    "\n",
    "while Jayden's is stored at \n",
    "\n",
    "`/home/Jayden/project/data/happiness_report.csv`.\n",
    " \n",
    "Even though Fatima and Jayden stored their files in the same place on their\n",
    "computers (in their home folders), the absolute paths are different due to\n",
    "their different usernames.  If Jayden has code that loads the\n",
    "`happiness_report.csv` data using an absolute path, the code won't work on\n",
    "Fatima's computer.  But the relative path from inside the `project` folder\n",
    "(`data/happiness_report.csv`) is the same on both computers; any code that uses\n",
    "relative paths will work on both!\n",
    "\n",
    "```{index} URL\n",
    "```\n",
    "\n",
    "Your file could be stored locally, as we discussed, or it could also be\n",
    "somewhere on the internet (remotely). A *Uniform Resource Locator (URL)* (web\n",
    "address) indicates the location of a resource on the internet and\n",
    "helps us retrieve that resource. Next, we will discuss how to get either\n",
    "locally or remotely stored data into Python. \n",
    "\n",
    "## Reading tabular data from a plain text file into Python\n",
    "\n",
    "(readcsv)=\n",
    "### `read_csv` to read in comma-separated files\n",
    "\n",
    "```{index} csv, reading; delimiter, read function; read\\_csv\n",
    "```\n",
    "\n",
    "Now that we have learned about *where* data could be, we will learn about *how*\n",
    "to import data into Python using various functions. Specifically, we will learn how \n",
    "to *read* tabular data from a plain text file (a document containing only text)\n",
    "*into* Python and *write* tabular data to a file *out of* Python. The function we use to do this\n",
    "depends on the file's format. For example, in the last chapter, we learned about using\n",
    "the `pandas` `read_csv` function when reading .csv (**c**omma-**s**eparated **v**alues)\n",
    "files. In that case, the separator or *delimiter* that divided our columns was a\n",
    "comma (`,`). We only learned the case where the data matched the expected defaults \n",
    "of the `read_csv` function \n",
    "(column names are present, and commas are used as the delimiter between columns). \n",
    "In this section, we will learn how to read \n",
    "files that do not satisfy the default expectations of `read_csv`.\n",
    "\n",
    "```{index} Canadian languages; canlang data\n",
    "```\n",
    "\n",
    "Before we jump into the cases where the data aren't in the expected default format \n",
    "for `pandas` and `read_csv`, let's revisit the more straightforward\n",
    "case where the defaults hold, and the only argument we need to give to the function\n",
    "is the path to the file, `data/can_lang.csv`. The `can_lang` data set contains \n",
    "language data from the 2016 Canadian census. \n",
    "We put `data/` before the file's\n",
    "name when we are loading the data set because this data set is located in a\n",
    "sub-folder, named `data`, relative to where we are running our Python code.\n",
    "\n",
    "Here is what the file would look like in a plain text editor (a program that removes\n",
    "all formatting, like bolding or different fonts):\n",
    "\n",
    "```code\n",
    "category,language,mother_tongue,most_at_home,most_at_work,lang_known\n",
    "Aboriginal languages,\"Aboriginal languages, n.o.s.\",590,235,30,665\n",
    "Non-Official & Non-Aboriginal languages,Afrikaans,10260,4785,85,23415\n",
    "Non-Official & Non-Aboriginal languages,\"Afro-Asiatic languages, n.i.e.\",1150,44\n",
    "Non-Official & Non-Aboriginal languages,Akan (Twi),13460,5985,25,22150\n",
    "Non-Official & Non-Aboriginal languages,Albanian,26895,13135,345,31930\n",
    "Aboriginal languages,\"Algonquian languages, n.i.e.\",45,10,0,120\n",
    "Aboriginal languages,Algonquin,1260,370,40,2480\n",
    "Non-Official & Non-Aboriginal languages,American Sign Language,2685,3020,1145,21\n",
    "Non-Official & Non-Aboriginal languages,Amharic,22465,12785,200,33670\n",
    "```\n",
    "\n",
    "```{index} pandas\n",
    "```\n",
    "\n",
    "And here is a review of how we can use `read_csv` to load it into Python. First we \n",
    "load the `pandas` package to gain access to useful\n",
    "functions for reading the data. \n",
    "\n",
    "Next we use `read_csv` to load the data into Python, and in that call we specify the\n",
    "relative path to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9df2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "canlang_data = pd.read_csv(\"data/can_lang.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df535004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>mother_tongue</th>\n",
       "      <th>most_at_home</th>\n",
       "      <th>most_at_work</th>\n",
       "      <th>lang_known</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Aboriginal languages, n.o.s.</td>\n",
       "      <td>590</td>\n",
       "      <td>235</td>\n",
       "      <td>30</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>10260</td>\n",
       "      <td>4785</td>\n",
       "      <td>85</td>\n",
       "      <td>23415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afro-Asiatic languages, n.i.e.</td>\n",
       "      <td>1150</td>\n",
       "      <td>445</td>\n",
       "      <td>10</td>\n",
       "      <td>2775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Akan (Twi)</td>\n",
       "      <td>13460</td>\n",
       "      <td>5985</td>\n",
       "      <td>25</td>\n",
       "      <td>22150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Albanian</td>\n",
       "      <td>26895</td>\n",
       "      <td>13135</td>\n",
       "      <td>345</td>\n",
       "      <td>31930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wolof</td>\n",
       "      <td>3990</td>\n",
       "      <td>1385</td>\n",
       "      <td>10</td>\n",
       "      <td>8240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Woods Cree</td>\n",
       "      <td>1840</td>\n",
       "      <td>800</td>\n",
       "      <td>75</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wu (Shanghainese)</td>\n",
       "      <td>12915</td>\n",
       "      <td>7650</td>\n",
       "      <td>105</td>\n",
       "      <td>16530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yiddish</td>\n",
       "      <td>13555</td>\n",
       "      <td>7085</td>\n",
       "      <td>895</td>\n",
       "      <td>20985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>9080</td>\n",
       "      <td>2615</td>\n",
       "      <td>15</td>\n",
       "      <td>22415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    category                        language  \\\n",
       "0                       Aboriginal languages    Aboriginal languages, n.o.s.   \n",
       "1    Non-Official & Non-Aboriginal languages                       Afrikaans   \n",
       "2    Non-Official & Non-Aboriginal languages  Afro-Asiatic languages, n.i.e.   \n",
       "3    Non-Official & Non-Aboriginal languages                      Akan (Twi)   \n",
       "4    Non-Official & Non-Aboriginal languages                        Albanian   \n",
       "..                                       ...                             ...   \n",
       "209  Non-Official & Non-Aboriginal languages                           Wolof   \n",
       "210                     Aboriginal languages                      Woods Cree   \n",
       "211  Non-Official & Non-Aboriginal languages               Wu (Shanghainese)   \n",
       "212  Non-Official & Non-Aboriginal languages                         Yiddish   \n",
       "213  Non-Official & Non-Aboriginal languages                          Yoruba   \n",
       "\n",
       "     mother_tongue  most_at_home  most_at_work  lang_known  \n",
       "0              590           235            30         665  \n",
       "1            10260          4785            85       23415  \n",
       "2             1150           445            10        2775  \n",
       "3            13460          5985            25       22150  \n",
       "4            26895         13135           345       31930  \n",
       "..             ...           ...           ...         ...  \n",
       "209           3990          1385            10        8240  \n",
       "210           1840           800            75        2665  \n",
       "211          12915          7650           105       16530  \n",
       "212          13555          7085           895       20985  \n",
       "213           9080          2615            15       22415  \n",
       "\n",
       "[214 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canlang_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4c785d",
   "metadata": {},
   "source": [
    "### Skipping rows when reading in data\n",
    "\n",
    "Oftentimes, information about how data was collected, or other relevant\n",
    "information, is included at the top of the data file. This information is\n",
    "usually written in sentence and paragraph form, with no delimiter because it is\n",
    "not organized into columns. An example of this is shown below. This information\n",
    "gives the data scientist useful context and information about the data,\n",
    "however, it is not well formatted or intended to be read into a data frame cell\n",
    "along with the tabular data that follows later in the file.\n",
    "\n",
    "```code\n",
    "Data source: https://ttimbers.github.io/canlang/\n",
    "Data originally published in: Statistics Canada Census of Population 2016.\n",
    "Reproduced and distributed on an as-is basis with their permission.\n",
    "category,language,mother_tongue,most_at_home,most_at_work,lang_known\n",
    "Aboriginal languages,\"Aboriginal languages, n.o.s.\",590,235,30,665\n",
    "Non-Official & Non-Aboriginal languages,Afrikaans,10260,4785,85,23415\n",
    "Non-Official & Non-Aboriginal languages,\"Afro-Asiatic languages, n.i.e.\",1150,44\n",
    "Non-Official & Non-Aboriginal languages,Akan (Twi),13460,5985,25,22150\n",
    "Non-Official & Non-Aboriginal languages,Albanian,26895,13135,345,31930\n",
    "Aboriginal languages,\"Algonquian languages, n.i.e.\",45,10,0,120\n",
    "Aboriginal languages,Algonquin,1260,370,40,2480\n",
    "Non-Official & Non-Aboriginal languages,American Sign Language,2685,3020,1145,21\n",
    "Non-Official & Non-Aboriginal languages,Amharic,22465,12785,200,33670\n",
    "```\n",
    "\n",
    "With this extra information being present at the top of the file, using\n",
    "`read_csv` as we did previously does not allow us to correctly load the data\n",
    "into Python. In the case of this file we end up only reading in one column of the\n",
    "data set:\n",
    "\n",
    "```\n",
    "\n",
    "canlang_data = pd.read_csv(\"data/can_lang-meta-data.csv\")\n",
    "```\n",
    "\n",
    "```\n",
    "ParserError: Error tokenizing data. C error: Expected 3 fields in line 3, saw 6\n",
    "```\n",
    "\n",
    "```{index} Error\n",
    "```\n",
    "\n",
    "> **Note:** In contrast to the normal and expected messages above, this time Python \n",
    "> printed out a Parsing error for us indicating that there might be a problem with how\n",
    "> our data is being read in.\n",
    "\n",
    "```{index} read function; skiprows argument\n",
    "```\n",
    "\n",
    "To successfully read data like this into Python, the `skiprows` \n",
    "argument can be useful to tell Python \n",
    "how many lines to skip before\n",
    "it should start reading in the data. In the example above, we would set this\n",
    "value to 2 and pass `header` as None to read and load the data correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e41ba2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Aboriginal languages, n.o.s.</td>\n",
       "      <td>590</td>\n",
       "      <td>235</td>\n",
       "      <td>30</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>10260</td>\n",
       "      <td>4785</td>\n",
       "      <td>85</td>\n",
       "      <td>23415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afro-Asiatic languages, n.i.e.</td>\n",
       "      <td>1150</td>\n",
       "      <td>445</td>\n",
       "      <td>10</td>\n",
       "      <td>2775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Akan (Twi)</td>\n",
       "      <td>13460</td>\n",
       "      <td>5985</td>\n",
       "      <td>25</td>\n",
       "      <td>22150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Albanian</td>\n",
       "      <td>26895</td>\n",
       "      <td>13135</td>\n",
       "      <td>345</td>\n",
       "      <td>31930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wolof</td>\n",
       "      <td>3990</td>\n",
       "      <td>1385</td>\n",
       "      <td>10</td>\n",
       "      <td>8240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Woods Cree</td>\n",
       "      <td>1840</td>\n",
       "      <td>800</td>\n",
       "      <td>75</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wu (Shanghainese)</td>\n",
       "      <td>12915</td>\n",
       "      <td>7650</td>\n",
       "      <td>105</td>\n",
       "      <td>16530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yiddish</td>\n",
       "      <td>13555</td>\n",
       "      <td>7085</td>\n",
       "      <td>895</td>\n",
       "      <td>20985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>9080</td>\n",
       "      <td>2615</td>\n",
       "      <td>15</td>\n",
       "      <td>22415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0                               1  \\\n",
       "0                       Aboriginal languages    Aboriginal languages, n.o.s.   \n",
       "1    Non-Official & Non-Aboriginal languages                       Afrikaans   \n",
       "2    Non-Official & Non-Aboriginal languages  Afro-Asiatic languages, n.i.e.   \n",
       "3    Non-Official & Non-Aboriginal languages                      Akan (Twi)   \n",
       "4    Non-Official & Non-Aboriginal languages                        Albanian   \n",
       "..                                       ...                             ...   \n",
       "423  Non-Official & Non-Aboriginal languages                           Wolof   \n",
       "424                     Aboriginal languages                      Woods Cree   \n",
       "425  Non-Official & Non-Aboriginal languages               Wu (Shanghainese)   \n",
       "426  Non-Official & Non-Aboriginal languages                         Yiddish   \n",
       "427  Non-Official & Non-Aboriginal languages                          Yoruba   \n",
       "\n",
       "         2      3    4      5  \n",
       "0      590    235   30    665  \n",
       "1    10260   4785   85  23415  \n",
       "2     1150    445   10   2775  \n",
       "3    13460   5985   25  22150  \n",
       "4    26895  13135  345  31930  \n",
       "..     ...    ...  ...    ...  \n",
       "423   3990   1385   10   8240  \n",
       "424   1840    800   75   2665  \n",
       "425  12915   7650  105  16530  \n",
       "426  13555   7085  895  20985  \n",
       "427   9080   2615   15  22415  \n",
       "\n",
       "[428 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canlang_data = pd.read_csv(\"data/can_lang-meta-data.csv\", skiprows=2, header=None)\n",
    "canlang_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb619c",
   "metadata": {},
   "source": [
    "How did we know to skip two lines? We looked at the data! The first two lines\n",
    "of the data had information we didn't need to import: \n",
    "\n",
    "```code\n",
    "Source: Statistics Canada, Census of Population, 2016. Reproduced and distributed on an \"as is\" basis with the permission of Statistics Canada.\n",
    "Date collected: 2020/07/09\n",
    "```\n",
    "\n",
    "The column names began at line 3, so we skipped the first two lines. \n",
    "\n",
    "### `read_csv` with `sep` argument to read in tab-separated files\n",
    "\n",
    "Another common way data is stored is with tabs as the delimiter. Notice the\n",
    "data file, `can_lang.tsv`, has tabs in between the columns instead of\n",
    "commas. \n",
    "\n",
    "```code\n",
    "category    language    mother_tongue   most_at_home    most_at_work    lang_kno\n",
    "Aboriginal languages    Aboriginal languages, n.o.s.    590 235 30  665\n",
    "Non-Official & Non-Aboriginal languages Afrikaans   10260   4785    85  23415\n",
    "Non-Official & Non-Aboriginal languages Afro-Asiatic languages, n.i.e.  1150    \n",
    "Non-Official & Non-Aboriginal languages Akan (Twi)  13460   5985    25  22150\n",
    "Non-Official & Non-Aboriginal languages Albanian    26895   13135   345 31930\n",
    "Aboriginal languages    Algonquian languages, n.i.e.    45  10  0   120\n",
    "Aboriginal languages    Algonquin   1260    370 40  2480\n",
    "Non-Official & Non-Aboriginal languages American Sign Language  2685    3020    \n",
    "Non-Official & Non-Aboriginal languages Amharic 22465   12785   200 33670\n",
    "```\n",
    "\n",
    "```{index} see: tab-separated values; tsv\n",
    "```\n",
    "\n",
    "```{index} tsv, read function; read_tsv\n",
    "```\n",
    "\n",
    "To read in this type of data, we can use the `read_csv` with `sep` argument \n",
    "to read in .tsv (**t**ab **s**eparated **v**alues) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01340919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Aboriginal languages, n.o.s.</td>\n",
       "      <td>590</td>\n",
       "      <td>235</td>\n",
       "      <td>30</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>10260</td>\n",
       "      <td>4785</td>\n",
       "      <td>85</td>\n",
       "      <td>23415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afro-Asiatic languages, n.i.e.</td>\n",
       "      <td>1150</td>\n",
       "      <td>445</td>\n",
       "      <td>10</td>\n",
       "      <td>2775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Akan (Twi)</td>\n",
       "      <td>13460</td>\n",
       "      <td>5985</td>\n",
       "      <td>25</td>\n",
       "      <td>22150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Albanian</td>\n",
       "      <td>26895</td>\n",
       "      <td>13135</td>\n",
       "      <td>345</td>\n",
       "      <td>31930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wolof</td>\n",
       "      <td>3990</td>\n",
       "      <td>1385</td>\n",
       "      <td>10</td>\n",
       "      <td>8240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Woods Cree</td>\n",
       "      <td>1840</td>\n",
       "      <td>800</td>\n",
       "      <td>75</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wu (Shanghainese)</td>\n",
       "      <td>12915</td>\n",
       "      <td>7650</td>\n",
       "      <td>105</td>\n",
       "      <td>16530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yiddish</td>\n",
       "      <td>13555</td>\n",
       "      <td>7085</td>\n",
       "      <td>895</td>\n",
       "      <td>20985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>9080</td>\n",
       "      <td>2615</td>\n",
       "      <td>15</td>\n",
       "      <td>22415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0                               1  \\\n",
       "0                       Aboriginal languages    Aboriginal languages, n.o.s.   \n",
       "1    Non-Official & Non-Aboriginal languages                       Afrikaans   \n",
       "2    Non-Official & Non-Aboriginal languages  Afro-Asiatic languages, n.i.e.   \n",
       "3    Non-Official & Non-Aboriginal languages                      Akan (Twi)   \n",
       "4    Non-Official & Non-Aboriginal languages                        Albanian   \n",
       "..                                       ...                             ...   \n",
       "209  Non-Official & Non-Aboriginal languages                           Wolof   \n",
       "210                     Aboriginal languages                      Woods Cree   \n",
       "211  Non-Official & Non-Aboriginal languages               Wu (Shanghainese)   \n",
       "212  Non-Official & Non-Aboriginal languages                         Yiddish   \n",
       "213  Non-Official & Non-Aboriginal languages                          Yoruba   \n",
       "\n",
       "         2      3    4      5  \n",
       "0      590    235   30    665  \n",
       "1    10260   4785   85  23415  \n",
       "2     1150    445   10   2775  \n",
       "3    13460   5985   25  22150  \n",
       "4    26895  13135  345  31930  \n",
       "..     ...    ...  ...    ...  \n",
       "209   3990   1385   10   8240  \n",
       "210   1840    800   75   2665  \n",
       "211  12915   7650  105  16530  \n",
       "212  13555   7085  895  20985  \n",
       "213   9080   2615   15  22415  \n",
       "\n",
       "[214 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canlang_data = pd.read_csv(\"data/can_lang.tsv\", sep=\"\\t\", header=None)\n",
    "canlang_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf0d06",
   "metadata": {},
   "source": [
    "Let's compare the data frame here to the resulting data frame in Section\n",
    "{ref}`readcsv` after using `read_csv`. Notice anything? They look the same! The\n",
    "same number of columns/rows and column names! So we needed to use different\n",
    "tools for the job depending on the file format and our resulting table\n",
    "(`canlang_data`) in both cases was the same! \n",
    "\n",
    "### `read_table` as a more flexible method to get tabular data into Python\n",
    "\n",
    "```{index} read function; read\\_delim, reading; delimiter\n",
    "```\n",
    "\n",
    "`read_csv` and `read_csv` with argument `sep` are actually just special cases of the more general\n",
    "`read_table` function. We can use\n",
    "`read_table` to import both comma and tab-separated files (and more), we just\n",
    "have to specify the delimiter. The `can_lang.tsv` is a different version of\n",
    "this same data set with no column names and uses tabs as the delimiter\n",
    "instead of commas. \n",
    "\n",
    "Here is how the file would look in a plain text editor:\n",
    "\n",
    "```code\n",
    "Aboriginal languages    Aboriginal languages, n.o.s.    590 235 30  665\n",
    "Non-Official & Non-Aboriginal languages Afrikaans   10260   4785    85  23415\n",
    "Non-Official & Non-Aboriginal languages Afro-Asiatic languages, n.i.e.  1150    \n",
    "Non-Official & Non-Aboriginal languages Akan (Twi)  13460   5985    25  22150\n",
    "Non-Official & Non-Aboriginal languages Albanian    26895   13135   345 31930\n",
    "Aboriginal languages    Algonquian languages, n.i.e.    45  10  0   120\n",
    "Aboriginal languages    Algonquin   1260    370 40  2480\n",
    "Non-Official & Non-Aboriginal languages American Sign Language  2685    3020    \n",
    "Non-Official & Non-Aboriginal languages Amharic 22465   12785   200 33670\n",
    "Non-Official & Non-Aboriginal languages Arabic  419890  223535  5585    629055\n",
    "```\n",
    "\n",
    "```{index} read function; sep argument\n",
    "```\n",
    "\n",
    "To get this into Python using the `read_table` function, we specify the first\n",
    "argument as the path to the file (as done with `read_csv`), and then provide\n",
    "values to the `sep` argument (here a\n",
    "tab, which we represent by `\"\\t\"`). \n",
    "\n",
    "```{index} escape character\n",
    "```\n",
    "\n",
    "> **Note:** `\\t` is an example of an *escaped character*, \n",
    "> which always starts with a backslash (`\\`).\n",
    "> Escaped characters are used to represent non-printing characters \n",
    "> (like the tab) or characters with special meanings (such as quotation marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d091f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Aboriginal languages, n.o.s.</td>\n",
       "      <td>590</td>\n",
       "      <td>235</td>\n",
       "      <td>30</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>10260</td>\n",
       "      <td>4785</td>\n",
       "      <td>85</td>\n",
       "      <td>23415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afro-Asiatic languages, n.i.e.</td>\n",
       "      <td>1150</td>\n",
       "      <td>445</td>\n",
       "      <td>10</td>\n",
       "      <td>2775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Akan (Twi)</td>\n",
       "      <td>13460</td>\n",
       "      <td>5985</td>\n",
       "      <td>25</td>\n",
       "      <td>22150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Albanian</td>\n",
       "      <td>26895</td>\n",
       "      <td>13135</td>\n",
       "      <td>345</td>\n",
       "      <td>31930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wolof</td>\n",
       "      <td>3990</td>\n",
       "      <td>1385</td>\n",
       "      <td>10</td>\n",
       "      <td>8240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Woods Cree</td>\n",
       "      <td>1840</td>\n",
       "      <td>800</td>\n",
       "      <td>75</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wu (Shanghainese)</td>\n",
       "      <td>12915</td>\n",
       "      <td>7650</td>\n",
       "      <td>105</td>\n",
       "      <td>16530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yiddish</td>\n",
       "      <td>13555</td>\n",
       "      <td>7085</td>\n",
       "      <td>895</td>\n",
       "      <td>20985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>9080</td>\n",
       "      <td>2615</td>\n",
       "      <td>15</td>\n",
       "      <td>22415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0                               1  \\\n",
       "0                       Aboriginal languages    Aboriginal languages, n.o.s.   \n",
       "1    Non-Official & Non-Aboriginal languages                       Afrikaans   \n",
       "2    Non-Official & Non-Aboriginal languages  Afro-Asiatic languages, n.i.e.   \n",
       "3    Non-Official & Non-Aboriginal languages                      Akan (Twi)   \n",
       "4    Non-Official & Non-Aboriginal languages                        Albanian   \n",
       "..                                       ...                             ...   \n",
       "209  Non-Official & Non-Aboriginal languages                           Wolof   \n",
       "210                     Aboriginal languages                      Woods Cree   \n",
       "211  Non-Official & Non-Aboriginal languages               Wu (Shanghainese)   \n",
       "212  Non-Official & Non-Aboriginal languages                         Yiddish   \n",
       "213  Non-Official & Non-Aboriginal languages                          Yoruba   \n",
       "\n",
       "         2      3    4      5  \n",
       "0      590    235   30    665  \n",
       "1    10260   4785   85  23415  \n",
       "2     1150    445   10   2775  \n",
       "3    13460   5985   25  22150  \n",
       "4    26895  13135  345  31930  \n",
       "..     ...    ...  ...    ...  \n",
       "209   3990   1385   10   8240  \n",
       "210   1840    800   75   2665  \n",
       "211  12915   7650  105  16530  \n",
       "212  13555   7085  895  20985  \n",
       "213   9080   2615   15  22415  \n",
       "\n",
       "[214 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canlang_data =  pd.read_csv(\"data/can_lang.tsv\", \n",
    "                           sep = \"\\t\", \n",
    "                           header = None)\n",
    "canlang_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b191aa61",
   "metadata": {},
   "source": [
    "Data frames in Python need to have column names.  Thus if you read in data that\n",
    "don't have column names, Python will assign names automatically. In the example\n",
    "above, Python assigns each column a name of `0, 1, 2, 3, 4, 5`.\n",
    "\n",
    "```{index} pandas.DataFrame; rename, pandas\n",
    "```\n",
    "\n",
    "It is best to rename your columns to help differentiate between them \n",
    "(e.g., `0, 1`, etc., are not very descriptive names and will make it more confusing as\n",
    "you code). To rename your columns, you can use the `rename` function\n",
    "from the [pandas package](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html#). \n",
    "The argument of the `rename` function is `columns`, which is a dictionary, \n",
    "where the keys are the old column names and values are the new column names.\n",
    "We rename the old `0, 1, ..., 5`\n",
    "columns in the `canlang_data` data frame to more descriptive names below, with the \n",
    "`inplace` argument as `True`, so that the columns are renamed in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f7eecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>mother_tongue</th>\n",
       "      <th>most_at_home</th>\n",
       "      <th>most_at_work</th>\n",
       "      <th>lang_known</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Aboriginal languages, n.o.s.</td>\n",
       "      <td>590</td>\n",
       "      <td>235</td>\n",
       "      <td>30</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>10260</td>\n",
       "      <td>4785</td>\n",
       "      <td>85</td>\n",
       "      <td>23415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afro-Asiatic languages, n.i.e.</td>\n",
       "      <td>1150</td>\n",
       "      <td>445</td>\n",
       "      <td>10</td>\n",
       "      <td>2775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Akan (Twi)</td>\n",
       "      <td>13460</td>\n",
       "      <td>5985</td>\n",
       "      <td>25</td>\n",
       "      <td>22150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Albanian</td>\n",
       "      <td>26895</td>\n",
       "      <td>13135</td>\n",
       "      <td>345</td>\n",
       "      <td>31930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wolof</td>\n",
       "      <td>3990</td>\n",
       "      <td>1385</td>\n",
       "      <td>10</td>\n",
       "      <td>8240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Woods Cree</td>\n",
       "      <td>1840</td>\n",
       "      <td>800</td>\n",
       "      <td>75</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wu (Shanghainese)</td>\n",
       "      <td>12915</td>\n",
       "      <td>7650</td>\n",
       "      <td>105</td>\n",
       "      <td>16530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yiddish</td>\n",
       "      <td>13555</td>\n",
       "      <td>7085</td>\n",
       "      <td>895</td>\n",
       "      <td>20985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>9080</td>\n",
       "      <td>2615</td>\n",
       "      <td>15</td>\n",
       "      <td>22415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    category                        language  \\\n",
       "0                       Aboriginal languages    Aboriginal languages, n.o.s.   \n",
       "1    Non-Official & Non-Aboriginal languages                       Afrikaans   \n",
       "2    Non-Official & Non-Aboriginal languages  Afro-Asiatic languages, n.i.e.   \n",
       "3    Non-Official & Non-Aboriginal languages                      Akan (Twi)   \n",
       "4    Non-Official & Non-Aboriginal languages                        Albanian   \n",
       "..                                       ...                             ...   \n",
       "209  Non-Official & Non-Aboriginal languages                           Wolof   \n",
       "210                     Aboriginal languages                      Woods Cree   \n",
       "211  Non-Official & Non-Aboriginal languages               Wu (Shanghainese)   \n",
       "212  Non-Official & Non-Aboriginal languages                         Yiddish   \n",
       "213  Non-Official & Non-Aboriginal languages                          Yoruba   \n",
       "\n",
       "     mother_tongue  most_at_home  most_at_work  lang_known  \n",
       "0              590           235            30         665  \n",
       "1            10260          4785            85       23415  \n",
       "2             1150           445            10        2775  \n",
       "3            13460          5985            25       22150  \n",
       "4            26895         13135           345       31930  \n",
       "..             ...           ...           ...         ...  \n",
       "209           3990          1385            10        8240  \n",
       "210           1840           800            75        2665  \n",
       "211          12915          7650           105       16530  \n",
       "212          13555          7085           895       20985  \n",
       "213           9080          2615            15       22415  \n",
       "\n",
       "[214 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canlang_data.rename(columns = {0:'category', \n",
    "                               1:'language',\n",
    "                               2:'mother_tongue',\n",
    "                               3:'most_at_home',\n",
    "                               4:'most_at_work',\n",
    "                               5:'lang_known'}, inplace = True)\n",
    "                               \n",
    "                               \n",
    "canlang_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246ba828",
   "metadata": {},
   "source": [
    "```{index} read function; names argument\n",
    "```\n",
    "\n",
    "The column names can also be assigned to the dataframe while reading it from the file by passing a \n",
    "list of column names to the `names` argument. `read_csv` and `read_table` have a `names` argument, \n",
    "whose default value is `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d178d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>mother_tongue</th>\n",
       "      <th>most_at_home</th>\n",
       "      <th>most_at_work</th>\n",
       "      <th>lang_known</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Aboriginal languages, n.o.s.</td>\n",
       "      <td>590</td>\n",
       "      <td>235</td>\n",
       "      <td>30</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>10260</td>\n",
       "      <td>4785</td>\n",
       "      <td>85</td>\n",
       "      <td>23415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afro-Asiatic languages, n.i.e.</td>\n",
       "      <td>1150</td>\n",
       "      <td>445</td>\n",
       "      <td>10</td>\n",
       "      <td>2775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Akan (Twi)</td>\n",
       "      <td>13460</td>\n",
       "      <td>5985</td>\n",
       "      <td>25</td>\n",
       "      <td>22150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Albanian</td>\n",
       "      <td>26895</td>\n",
       "      <td>13135</td>\n",
       "      <td>345</td>\n",
       "      <td>31930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wolof</td>\n",
       "      <td>3990</td>\n",
       "      <td>1385</td>\n",
       "      <td>10</td>\n",
       "      <td>8240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Woods Cree</td>\n",
       "      <td>1840</td>\n",
       "      <td>800</td>\n",
       "      <td>75</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wu (Shanghainese)</td>\n",
       "      <td>12915</td>\n",
       "      <td>7650</td>\n",
       "      <td>105</td>\n",
       "      <td>16530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yiddish</td>\n",
       "      <td>13555</td>\n",
       "      <td>7085</td>\n",
       "      <td>895</td>\n",
       "      <td>20985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>9080</td>\n",
       "      <td>2615</td>\n",
       "      <td>15</td>\n",
       "      <td>22415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    category                        language  \\\n",
       "0                       Aboriginal languages    Aboriginal languages, n.o.s.   \n",
       "1    Non-Official & Non-Aboriginal languages                       Afrikaans   \n",
       "2    Non-Official & Non-Aboriginal languages  Afro-Asiatic languages, n.i.e.   \n",
       "3    Non-Official & Non-Aboriginal languages                      Akan (Twi)   \n",
       "4    Non-Official & Non-Aboriginal languages                        Albanian   \n",
       "..                                       ...                             ...   \n",
       "209  Non-Official & Non-Aboriginal languages                           Wolof   \n",
       "210                     Aboriginal languages                      Woods Cree   \n",
       "211  Non-Official & Non-Aboriginal languages               Wu (Shanghainese)   \n",
       "212  Non-Official & Non-Aboriginal languages                         Yiddish   \n",
       "213  Non-Official & Non-Aboriginal languages                          Yoruba   \n",
       "\n",
       "     mother_tongue  most_at_home  most_at_work  lang_known  \n",
       "0              590           235            30         665  \n",
       "1            10260          4785            85       23415  \n",
       "2             1150           445            10        2775  \n",
       "3            13460          5985            25       22150  \n",
       "4            26895         13135           345       31930  \n",
       "..             ...           ...           ...         ...  \n",
       "209           3990          1385            10        8240  \n",
       "210           1840           800            75        2665  \n",
       "211          12915          7650           105       16530  \n",
       "212          13555          7085           895       20985  \n",
       "213           9080          2615            15       22415  \n",
       "\n",
       "[214 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canlang_data = pd.read_csv(\n",
    "    \"data/can_lang.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"category\",\n",
    "        \"language\",\n",
    "        \"mother_tongue\",\n",
    "        \"most_at_home\",\n",
    "        \"most_at_work\",\n",
    "        \"lang_known\",\n",
    "    ],\n",
    ")\n",
    "canlang_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ed6a2",
   "metadata": {},
   "source": [
    "### Reading tabular data directly from a URL\n",
    "\n",
    "```{index} URL; reading from\n",
    "```\n",
    "\n",
    "We can also use `read_csv`, `read_table`(and related functions)\n",
    "to read in data directly from a **U**niform **R**esource **L**ocator (URL) that\n",
    "contains tabular data. Here, we provide the URL to\n",
    "`read_*` as the path to the file instead of a path to a local file on our\n",
    "computer. We need to surround the URL with quotes similar to when we specify a\n",
    "path on our local computer. All other arguments that we use are the same as\n",
    "when using these functions with a local file on our computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f211d8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>mother_tongue</th>\n",
       "      <th>most_at_home</th>\n",
       "      <th>most_at_work</th>\n",
       "      <th>lang_known</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Aboriginal languages, n.o.s.</td>\n",
       "      <td>590</td>\n",
       "      <td>235</td>\n",
       "      <td>30</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>10260</td>\n",
       "      <td>4785</td>\n",
       "      <td>85</td>\n",
       "      <td>23415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afro-Asiatic languages, n.i.e.</td>\n",
       "      <td>1150</td>\n",
       "      <td>445</td>\n",
       "      <td>10</td>\n",
       "      <td>2775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Akan (Twi)</td>\n",
       "      <td>13460</td>\n",
       "      <td>5985</td>\n",
       "      <td>25</td>\n",
       "      <td>22150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Albanian</td>\n",
       "      <td>26895</td>\n",
       "      <td>13135</td>\n",
       "      <td>345</td>\n",
       "      <td>31930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wolof</td>\n",
       "      <td>3990</td>\n",
       "      <td>1385</td>\n",
       "      <td>10</td>\n",
       "      <td>8240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Woods Cree</td>\n",
       "      <td>1840</td>\n",
       "      <td>800</td>\n",
       "      <td>75</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wu (Shanghainese)</td>\n",
       "      <td>12915</td>\n",
       "      <td>7650</td>\n",
       "      <td>105</td>\n",
       "      <td>16530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yiddish</td>\n",
       "      <td>13555</td>\n",
       "      <td>7085</td>\n",
       "      <td>895</td>\n",
       "      <td>20985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>9080</td>\n",
       "      <td>2615</td>\n",
       "      <td>15</td>\n",
       "      <td>22415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    category                        language  \\\n",
       "0                       Aboriginal languages    Aboriginal languages, n.o.s.   \n",
       "1    Non-Official & Non-Aboriginal languages                       Afrikaans   \n",
       "2    Non-Official & Non-Aboriginal languages  Afro-Asiatic languages, n.i.e.   \n",
       "3    Non-Official & Non-Aboriginal languages                      Akan (Twi)   \n",
       "4    Non-Official & Non-Aboriginal languages                        Albanian   \n",
       "..                                       ...                             ...   \n",
       "209  Non-Official & Non-Aboriginal languages                           Wolof   \n",
       "210                     Aboriginal languages                      Woods Cree   \n",
       "211  Non-Official & Non-Aboriginal languages               Wu (Shanghainese)   \n",
       "212  Non-Official & Non-Aboriginal languages                         Yiddish   \n",
       "213  Non-Official & Non-Aboriginal languages                          Yoruba   \n",
       "\n",
       "     mother_tongue  most_at_home  most_at_work  lang_known  \n",
       "0              590           235            30         665  \n",
       "1            10260          4785            85       23415  \n",
       "2             1150           445            10        2775  \n",
       "3            13460          5985            25       22150  \n",
       "4            26895         13135           345       31930  \n",
       "..             ...           ...           ...         ...  \n",
       "209           3990          1385            10        8240  \n",
       "210           1840           800            75        2665  \n",
       "211          12915          7650           105       16530  \n",
       "212          13555          7085           895       20985  \n",
       "213           9080          2615            15       22415  \n",
       "\n",
       "[214 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience-python/reading/source/data/can_lang.csv\"\n",
    "pd.read_csv(url)\n",
    "canlang_data = pd.read_csv(url)\n",
    "\n",
    "canlang_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053329d5",
   "metadata": {},
   "source": [
    "### Previewing a data file before reading it into Python\n",
    "\n",
    "In all the examples above, we gave you previews of the data file before we read\n",
    "it into Python. Previewing data is essential to see whether or not there are column\n",
    "names, what the delimiters are, and if there are lines you need to skip. You\n",
    "should do this yourself when trying to read in data files. You can preview\n",
    "files in a plain text editor by right-clicking on the file, selecting \"Open\n",
    "With,\" and choosing a plain text editor (e.g., Notepad). \n",
    "\n",
    "## Reading tabular data from a Microsoft Excel file\n",
    "\n",
    "```{index} Excel spreadsheet\n",
    "```\n",
    "\n",
    "```{index} see: Microsoft Excel; Excel spreadsheet\n",
    "```\n",
    "\n",
    "```{index} see: xlsx; Excel spreadsheet\n",
    "```\n",
    "\n",
    "There are many other ways to store tabular data sets beyond plain text files,\n",
    "and similarly, many ways to load those data sets into Python. For example, it is\n",
    "very common to encounter, and need to load into Python, data stored as a Microsoft\n",
    "Excel spreadsheet (with the file name\n",
    "extension `.xlsx`).  To be able to do this, a key thing to know is that even\n",
    "though `.csv` and `.xlsx` files look almost identical when loaded into Excel,\n",
    "the data themselves are stored completely differently.  While `.csv` files are\n",
    "plain text files, where the characters you see when you open the file in a text\n",
    "editor are exactly the data they represent, this is not the case for `.xlsx`\n",
    "files. Take a look at a snippet of what a `.xlsx` file would look like in a text editor:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92f6504",
   "metadata": {},
   "source": [
    "```\n",
    ",?'O\n",
    "    _rels/.rels???J1??>E?{7?\n",
    "<?V????w8?'J???'QrJ???Tf?d??d?o?wZ'???@>?4'?|??hlIo??F\n",
    "t                                                       8f??3wn\n",
    "????t??u\"/\n",
    "          %~Ed2??<?w??\n",
    "                       ?Pd(??J-?E???7?'t(?-GZ?????y???c~N?g[^_r?4\n",
    "                                                                  yG?O\n",
    "                                                                      ?K??G?\n",
    "                                                                      \n",
    "                                                                                                                    \n",
    "     ]TUEe??O??c[???????6q??s??d?m???\\???H?^????3} ?rZY? ?:L60?^?????XTP+?|?\n",
    "X?a??4VT?,D?Jq\n",
    "```\n",
    "\n",
    "```{index} read function; read_excel\n",
    "```\n",
    "\n",
    "This type of file representation allows Excel files to store additional things\n",
    "that you cannot store in a `.csv` file, such as fonts, text formatting,\n",
    "graphics, multiple sheets and more. And despite looking odd in a plain text\n",
    "editor, we can read Excel spreadsheets into Python using the `pandas` package's `read_excel` \n",
    "function developed specifically for this \n",
    "purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0811dd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>mother_tongue</th>\n",
       "      <th>most_at_home</th>\n",
       "      <th>most_at_work</th>\n",
       "      <th>lang_known</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Aboriginal languages, n.o.s.</td>\n",
       "      <td>590</td>\n",
       "      <td>235</td>\n",
       "      <td>30</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>10260</td>\n",
       "      <td>4785</td>\n",
       "      <td>85</td>\n",
       "      <td>23415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Afro-Asiatic languages, n.i.e.</td>\n",
       "      <td>1150</td>\n",
       "      <td>445</td>\n",
       "      <td>10</td>\n",
       "      <td>2775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Akan (Twi)</td>\n",
       "      <td>13460</td>\n",
       "      <td>5985</td>\n",
       "      <td>25</td>\n",
       "      <td>22150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Albanian</td>\n",
       "      <td>26895</td>\n",
       "      <td>13135</td>\n",
       "      <td>345</td>\n",
       "      <td>31930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wolof</td>\n",
       "      <td>3990</td>\n",
       "      <td>1385</td>\n",
       "      <td>10</td>\n",
       "      <td>8240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Aboriginal languages</td>\n",
       "      <td>Woods Cree</td>\n",
       "      <td>1840</td>\n",
       "      <td>800</td>\n",
       "      <td>75</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Wu (Shanghainese)</td>\n",
       "      <td>12915</td>\n",
       "      <td>7650</td>\n",
       "      <td>105</td>\n",
       "      <td>16530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yiddish</td>\n",
       "      <td>13555</td>\n",
       "      <td>7085</td>\n",
       "      <td>895</td>\n",
       "      <td>20985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Non-Official &amp; Non-Aboriginal languages</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>9080</td>\n",
       "      <td>2615</td>\n",
       "      <td>15</td>\n",
       "      <td>22415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    category                        language  \\\n",
       "0                       Aboriginal languages    Aboriginal languages, n.o.s.   \n",
       "1    Non-Official & Non-Aboriginal languages                       Afrikaans   \n",
       "2    Non-Official & Non-Aboriginal languages  Afro-Asiatic languages, n.i.e.   \n",
       "3    Non-Official & Non-Aboriginal languages                      Akan (Twi)   \n",
       "4    Non-Official & Non-Aboriginal languages                        Albanian   \n",
       "..                                       ...                             ...   \n",
       "209  Non-Official & Non-Aboriginal languages                           Wolof   \n",
       "210                     Aboriginal languages                      Woods Cree   \n",
       "211  Non-Official & Non-Aboriginal languages               Wu (Shanghainese)   \n",
       "212  Non-Official & Non-Aboriginal languages                         Yiddish   \n",
       "213  Non-Official & Non-Aboriginal languages                          Yoruba   \n",
       "\n",
       "     mother_tongue  most_at_home  most_at_work  lang_known  \n",
       "0              590           235            30         665  \n",
       "1            10260          4785            85       23415  \n",
       "2             1150           445            10        2775  \n",
       "3            13460          5985            25       22150  \n",
       "4            26895         13135           345       31930  \n",
       "..             ...           ...           ...         ...  \n",
       "209           3990          1385            10        8240  \n",
       "210           1840           800            75        2665  \n",
       "211          12915          7650           105       16530  \n",
       "212          13555          7085           895       20985  \n",
       "213           9080          2615            15       22415  \n",
       "\n",
       "[214 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canlang_data = pd.read_excel(\"data/can_lang.xlsx\")\n",
    "canlang_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146e72c",
   "metadata": {},
   "source": [
    "If the `.xlsx` file has multiple sheets, you have to use the `sheet_name` argument\n",
    "to specify the sheet number or name. You can also specify cell ranges using the\n",
    "`usecols` argument(Example:  `usecols=\"A:D\"` for including cells from `A` to `D`). \n",
    "This functionality is useful when a single sheet contains\n",
    "multiple tables (a sad thing that happens to many Excel spreadsheets since this\n",
    "makes reading in data more difficult). \n",
    "\n",
    "As with plain text files, you should always explore the data file before\n",
    "importing it into Python. Exploring the data beforehand helps you decide which\n",
    "arguments you need to load the data into Python successfully. If you do not have\n",
    "the Excel program on your computer, you can use other programs to preview the\n",
    "file. Examples include Google Sheets and Libre Office. \n",
    "\n",
    "In {numref}`read_func` we summarize the `read_*` functions we covered\n",
    "in this chapter. We also include the `read_csv2` function for data separated by\n",
    "semicolons `;`, which you may run into with data sets where the decimal is\n",
    "represented by a comma instead of a period (as with some data sets from\n",
    "European countries).\n",
    "\n",
    "\n",
    "```{list-table} Summary of read_* functions\n",
    ":header-rows: 1\n",
    ":name: read_func\n",
    "\n",
    "* - Data File Type\n",
    "  - Python Function\n",
    "  - Python Package\n",
    "* - Comma (`,`) separated files\n",
    "  - `read_csv`\n",
    "  - `pandas`\n",
    "* - Tab (`\\t`) separated files \n",
    "  - `read_csv` with `sep` argument\n",
    "  - `pandas`\n",
    "* - Semicolon (`;`) separated files\n",
    "  - `read_csv` with `sep` argument\n",
    "  - `pandas`\n",
    "* - Various formats (`.csv`, `.tsv`) \n",
    "  - `read_table`\n",
    "  - `pandas`\n",
    "* - Excel files (`.xlsx`)\n",
    "  - `read_excel`\n",
    "  - `pandas`\n",
    "  \n",
    "  \n",
    "```\n",
    "\n",
    "## Reading data from a database\n",
    "\n",
    "```{index} database\n",
    "```\n",
    "\n",
    "Another very common form of data storage is the relational database. Databases\n",
    "are great when you have large data sets or multiple users\n",
    "working on a project. There are many relational database management systems,\n",
    "such as SQLite, MySQL, PostgreSQL, Oracle, and many more. These\n",
    "different relational database management systems each have their own advantages\n",
    "and limitations. Almost all employ SQL (*structured query language*) to obtain\n",
    "data from the database. But you don't need to know SQL to analyze data from\n",
    "a database; several packages have been written that allow you to connect to\n",
    "relational databases and use the Python programming language \n",
    "to obtain data. In this book, we will give examples of how to do this\n",
    "using Python with SQLite and PostgreSQL databases.\n",
    "\n",
    "### Reading data from a SQLite database\n",
    "\n",
    "```{index} database; SQLite\n",
    "```\n",
    "\n",
    "SQLite is probably the simplest relational database system\n",
    "that one can use in combination with Python. SQLite databases are self-contained and\n",
    "usually stored and accessed locally on one computer. Data is usually stored in\n",
    "a file with a `.db` extension. Similar to Excel files, these are not plain text\n",
    "files and cannot be read in a plain text editor. \n",
    "\n",
    "```{index} database; connect, SQLAlchemy, SQLAlchemy; create_engine, database; SQLAlchemy\n",
    "```\n",
    "\n",
    "```{index} see: SQLAlchemy; database\n",
    "```\n",
    "\n",
    "The first thing you need to do to read data into Python from a database is to\n",
    "connect to the database. We do that using the `create_engine` function from the\n",
    "`sal` (SQLAlchemy) package. This does not read\n",
    "in the data, but simply tells Python where the database is and opens up a\n",
    "communication channel that Python can use to send SQL commands to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7412d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sal\n",
    "from sqlalchemy import MetaData, Table, create_engine, select\n",
    "\n",
    "db = sal.create_engine(\"sqlite:///data/can_lang.db\")\n",
    "conn = db.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d26faa",
   "metadata": {},
   "source": [
    "```{index} database; tables\n",
    "```\n",
    "\n",
    "Often relational databases have many tables; thus, in order to retrieve\n",
    "data from a database, you need to know the name of the table \n",
    "in which the data is stored. You can get the names of\n",
    "all the tables in the database using the `table_names`\n",
    "function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca095aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['can_lang']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = db.table_names()\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b0ef3c",
   "metadata": {},
   "source": [
    "```{index} database; select, SQLAlchemy; select\n",
    "```\n",
    "\n",
    "The `table_names` function returned only one name, which tells us\n",
    "that there is only one table in this database. To reference a table in the\n",
    "database (so that we can perform operations like selecting columns and filtering rows), we \n",
    "use the `select` function from the `sqlalchemy` package. The object returned\n",
    "by the `select` function allows us to work with data\n",
    "stored in databases as if they were just regular data frames; but secretly, behind\n",
    "the scenes, `sqlalchemy` is turning your function calls (e.g., `select`)\n",
    "into SQL queries! To access the table in the database, we first declare the `metadata` of the table using\n",
    "`sqlalchemy` package and then access the table using `select` function from `sqlalchemy` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "049b1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData(bind=None)\n",
    "table = Table(\n",
    "    'can_lang', \n",
    "    metadata, \n",
    "    autoload=True, \n",
    "    autoload_with=db\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf557ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x1151f8bb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = select([table])\n",
    "canlang_data_db = conn.execute(query)\n",
    "canlang_data_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2ec22",
   "metadata": {},
   "source": [
    "```{index} database; fetchall, SQLAlchemy; fetchall\n",
    "```\n",
    "\n",
    "Although it looks like we just got a data frame from the database, we didn't!\n",
    "It's a *reference*; the data is still stored only in the SQLite database. The output \n",
    "is a `CursorResult`(indicating that Python does not know how many rows \n",
    "there are in total!) object.\n",
    "In order to actually retrieve this data in Python,\n",
    "we use the `fetchall()` function. The\n",
    "`sqlalchemy` package works this way because databases are often more efficient at selecting, filtering\n",
    "and joining large data sets than Python. And typically the database will not even\n",
    "be stored on your computer, but rather a more powerful machine somewhere on the\n",
    "web. So Python is lazy and waits to bring this data into memory until you explicitly\n",
    "tell it to using the `fetchall` function. The `fetchall` function returns the \n",
    "result of the query in the form of a list, where each row in the table is an element in the list.\n",
    "Let's look at the first 10 rows in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "481ebb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Aboriginal languages', 'Aboriginal languages, n.o.s.', 590.0, 235.0, 30.0, 665.0),\n",
       " ('Non-Official & Non-Aboriginal languages', 'Afrikaans', 10260.0, 4785.0, 85.0, 23415.0),\n",
       " ('Non-Official & Non-Aboriginal languages', 'Afro-Asiatic languages, n.i.e.', 1150.0, 445.0, 10.0, 2775.0),\n",
       " ('Non-Official & Non-Aboriginal languages', 'Akan (Twi)', 13460.0, 5985.0, 25.0, 22150.0),\n",
       " ('Non-Official & Non-Aboriginal languages', 'Albanian', 26895.0, 13135.0, 345.0, 31930.0),\n",
       " ('Aboriginal languages', 'Algonquian languages, n.i.e.', 45.0, 10.0, 0.0, 120.0),\n",
       " ('Aboriginal languages', 'Algonquin', 1260.0, 370.0, 40.0, 2480.0),\n",
       " ('Non-Official & Non-Aboriginal languages', 'American Sign Language', 2685.0, 3020.0, 1145.0, 21930.0),\n",
       " ('Non-Official & Non-Aboriginal languages', 'Amharic', 22465.0, 12785.0, 200.0, 33670.0),\n",
       " ('Non-Official & Non-Aboriginal languages', 'Arabic', 419890.0, 223535.0, 5585.0, 629055.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canlang_data_db = conn.execute(query).fetchall()\n",
    "canlang_data_db[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6abb4ba",
   "metadata": {},
   "source": [
    "```{index} database; show query, SQLAlchemy; query.compile\n",
    "```\n",
    "\n",
    "We can look at the SQL commands that are sent to the database when we write \n",
    "`conn.execute(query).fetchall()` in Python with the `query.compile` function from the\n",
    "`sqlalchemy` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6716ef58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT can_lang.category, can_lang.language, can_lang.mother_tongue, can_lang.most_at_home, can_lang.most_at_work, can_lang.lang_known \n",
      "FROM can_lang\n"
     ]
    }
   ],
   "source": [
    "compiled = query.compile(db, compile_kwargs={\"render_postcompile\": True})\n",
    "\n",
    "print(str(compiled) % compiled.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e26bb5",
   "metadata": {},
   "source": [
    "The output above shows the SQL code that is sent to the database. When we\n",
    "write `conn.execute(query).fetchall()` in Python, in the background, the function is\n",
    "translating the Python code into SQL, sending that SQL to the database, and then translating the\n",
    "response for us. So `sqlalchemy` does all the hard work of translating from Python to SQL and back for us; \n",
    "we can just stick with Python! \n",
    "\n",
    "With our `canlang_data_db` table reference for the 2016 Canadian Census data in hand, we \n",
    "can mostly continue onward as if it were a regular data frame. For example, \n",
    "we can use the `select` function along with `where` function\n",
    "to obtain only certain rows. Below we filter the data to include only Aboriginal languages using \n",
    "the `where` function of `sqlalchemy`\n",
    "\n",
    "```{index} database; filter data, SQLAlchemy; where\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "317e73e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x11524ceb0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = select([table]).where(table.columns.category == 'Aboriginal languages')\n",
    "result_proxy = conn.execute(query)\n",
    "result_proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b280acaa",
   "metadata": {},
   "source": [
    "```{index} database; fetchall, SQLAlchemy; fetchall\n",
    "```\n",
    "\n",
    "Above you can again see that this data is not actually stored in Python yet:\n",
    "the output is a `CursorResult`(indicating that Python does not know how many rows \n",
    "there are in total!) object.\n",
    "In order to actually retrieve this data in Python as a data frame,\n",
    "we again use the `fetchall()` function. \n",
    "Below you will see that after running `fetchall()`, Python knows that the retrieved\n",
    "data has 67 rows, and there is no `CursorResult` object listed any more. We will display only the first 10 \n",
    "rows of the table from the list returned by the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e77acad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Aboriginal languages', 'Aboriginal languages, n.o.s.', 590.0, 235.0, 30.0, 665.0),\n",
       " ('Aboriginal languages', 'Algonquian languages, n.i.e.', 45.0, 10.0, 0.0, 120.0),\n",
       " ('Aboriginal languages', 'Algonquin', 1260.0, 370.0, 40.0, 2480.0),\n",
       " ('Aboriginal languages', 'Athabaskan languages, n.i.e.', 50.0, 10.0, 0.0, 85.0),\n",
       " ('Aboriginal languages', 'Atikamekw', 6150.0, 5465.0, 1100.0, 6645.0),\n",
       " ('Aboriginal languages', \"Babine (Wetsuwet'en)\", 110.0, 20.0, 10.0, 210.0),\n",
       " ('Aboriginal languages', 'Beaver', 190.0, 50.0, 0.0, 340.0),\n",
       " ('Aboriginal languages', 'Blackfoot', 2815.0, 1110.0, 85.0, 5645.0),\n",
       " ('Aboriginal languages', 'Carrier', 1025.0, 250.0, 15.0, 2100.0),\n",
       " ('Aboriginal languages', 'Cayuga', 45.0, 10.0, 10.0, 125.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aboriginal_lang_data_db = result_proxy.fetchall()\n",
    "aboriginal_lang_data_db[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a2c05",
   "metadata": {},
   "source": [
    "`sqlalchemy` provides many more functions (not just `select`, `where`) \n",
    "that you can use to directly feed the database reference (`aboriginal_lang_data_db`) into \n",
    "downstream analysis functions (e.g., `altair` for data visualization). \n",
    "But `sqlalchemy` does not provide *every* function that we need for analysis;\n",
    "we do eventually need to call `fetchall`.\n",
    "\n",
    "```{index} pandas.DataFrame; shape\n",
    "```\n",
    "\n",
    "Does the result returned by `fetchall` function store it as a dataframe? Let's look \n",
    "what happens when we try to use `shape` to count rows in a dataframe\n",
    "\n",
    "```\n",
    "aboriginal_lang_data_db.shape\n",
    "```\n",
    "\n",
    "```\n",
    "## AttributeError: 'list' object has no attribute 'shape'\n",
    "```\n",
    "\n",
    "```{index} pandas.DataFrame; tail\n",
    "```\n",
    "\n",
    "or `tail` to preview the last six rows of a data frame:\n",
    "\n",
    "```\n",
    "aboriginal_lang_data_db.tail(6)\n",
    "```\n",
    "\n",
    "```\n",
    "## AttributeError: 'list' object has no attribute 'tail'\n",
    "```\n",
    "\n",
    "Oops! We cannot treat the result as a dataframe, hence we need to convert it \n",
    "to a dataframe after calling `fetchall` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3588d757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aboriginal_lang_data_db = pd.DataFrame(aboriginal_lang_data_db, columns=['category', 'language', 'mother_tongue', 'most_at_home', 'most_at_work', 'lang_known'])\n",
    "aboriginal_lang_data_db.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d024f7",
   "metadata": {},
   "source": [
    ">\n",
    "> Additionally, some operations will not work to extract columns or single values\n",
    "> from the reference. Thus, once you have finished\n",
    "> your data wrangling of the database reference object, it is advisable to\n",
    "> bring it into Python using `fetchall` and then converting it into the dataframe using `pandas` package.\n",
    "> But be very careful using `fetchall`: databases are often *very* big,\n",
    "> and reading an entire table into Python might take a long time to run or even possibly\n",
    "> crash your machine. So make sure you use `where` and `select` on the database table\n",
    "> to reduce the data to a reasonable size before using `fetchall` to read it into Python!\n",
    " \n",
    "### Reading data from a PostgreSQL database \n",
    "\n",
    "```{index} database; PostgreSQL\n",
    "```\n",
    "\n",
    "PostgreSQL (also called Postgres) is a very popular\n",
    "and open-source option for relational database software. \n",
    "Unlike SQLite,\n",
    "PostgreSQL uses a client–server database engine, as it was designed to be used\n",
    "and accessed on a network. This means that you have to provide more information\n",
    "to Python when connecting to Postgres databases. The additional information that you\n",
    "need to include when you call the `create_engine` function is listed below:\n",
    "\n",
    "- `dbname`: the name of the database (a single PostgreSQL instance can host more than one database)\n",
    "- `host`: the URL pointing to where the database is located\n",
    "- `port`: the communication endpoint between Python and the PostgreSQL database (usually `5432`)\n",
    "- `user`: the username for accessing the database\n",
    "- `password`: the password for accessing the database\n",
    "\n",
    "Additionally, we must use the `pgdb` package instead of `sqlalchemy` in the\n",
    "`create_engine` function call.  Below we demonstrate how to connect to a version of\n",
    "the `can_mov_db` database, which contains information about Canadian movies.\n",
    "Note that the `host` (`fakeserver.stat.ubc.ca`), `user` (`user0001`), and \n",
    "`password` (`abc123`) below are *not real*; you will not actually \n",
    "be able to connect to a database using this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1c18b26",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pgdb in /opt/miniconda3/lib/python3.9/site-packages (0.0.11)\n",
      "Requirement already satisfied: psycopg2-binary>=2.8.2 in /opt/miniconda3/lib/python3.9/site-packages (from pgdb) (2.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pgdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140a414",
   "metadata": {},
   "source": [
    "```\n",
    "!pip install pgdb\n",
    "import pgdb\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# connection_str = \"postgresql://<USERNAME>:<PASSWORD>@<IP_ADDRESS>:<PORT>/<DATABASE_NAME>\"\n",
    "connection_str = \"postgresql://user0001:abc123@fakeserver.stat.ubc.ca:5432/can_mov_db\"\n",
    "db = create_engine(connection_str)\n",
    "conn_mov_data = db.connect()\n",
    "\n",
    "```\n",
    "\n",
    "After opening the connection, everything looks and behaves almost identically\n",
    "to when we were using an SQLite database in Python. For example, we can again use\n",
    "`table_names` to find out what tables are in the `can_mov_db` database:\n",
    "\n",
    "```\n",
    "tables = conn_mov_data.table_names()\n",
    "tables\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "['themes', 'medium', 'titles', 'title_aliases', 'forms', 'episodes', 'names', 'names_occupations', 'occupation', 'ratings']\n",
    "\n",
    "```\n",
    "\n",
    "We see that there are 10 tables in this database. Let's first look at the\n",
    "`\"ratings\"` table to find the lowest rating that exists in the `can_mov_db`\n",
    "database. To access the table's contents we first need to declare the `metadata` of the table \n",
    "and store it in a variable named `ratings`. Then, we can use the `select` function to \n",
    "refer to the data in the table and return the result in python using `fetchall` function, just like \n",
    "we did for the SQLite database.\n",
    "\n",
    "```\n",
    "metadata = MetaData(bind=None)\n",
    "ratings = Table(\n",
    "    'ratings', \n",
    "    metadata, \n",
    "    autoload=True, \n",
    "    autoload_with=db\n",
    ")\n",
    "\n",
    "query = select([ratings])\n",
    "ratings_proxy = conn_mov_data.execute(query).fetchall()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "[('The Grand Seduction', 6.6, 150),\n",
    "('Rhymes for Young Ghouls', 6.3, 1685),\n",
    "('Mommy', 7.5, 1060),\n",
    "('Incendies', 6.1, 1101),\n",
    "('Bon Cop, Bad Cop', 7.0, 894),\n",
    "('Goon', 5.5, 1111),\n",
    "('Monsieur Lazhar', 5.6,610),\n",
    "('What if', 5.3, 1401),\n",
    "('The Barbarian Invations', 5.8, 99\n",
    "('Away from Her', 6.9, 2311)]\n",
    "\n",
    "```\n",
    "\n",
    "```{index} SQLAlchemy; select\n",
    "```\n",
    "\n",
    "To find the lowest rating that exists in the data base, we first need to\n",
    "extract the `average_rating` column using `select`:\n",
    "\n",
    "```\n",
    "avg_rating_db = select([ratings.columns.average_rating])\n",
    "avg_rating_db\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "[(6.6,),\n",
    " (6.3,),\n",
    " (7.5,),\n",
    " (6.1,),\n",
    " (7.0,),\n",
    " (5.5,),\n",
    " (5.6,),\n",
    " (5.4,),\n",
    " (5.8,),\n",
    " (6.9,)]\n",
    "```\n",
    "\n",
    "```{index} min\n",
    "```\n",
    "\n",
    "Next we use `min` to find the minimum rating in that column:\n",
    "\n",
    "```\n",
    "min(avg_rating_db)\n",
    "```\n",
    "\n",
    "```\n",
    "(1.0,)\n",
    "```\n",
    "\n",
    "We see the lowest rating given to a movie is 1, indicating that it must have\n",
    "been a really bad movie...\n",
    "\n",
    "### Why should we bother with databases at all?\n",
    "\n",
    "```{index} database; reasons to use\n",
    "```\n",
    "\n",
    "Opening a database stored in a `.db` file\n",
    "involved a lot more effort than just opening a `.csv`, or any of the\n",
    "other plain text or Excel formats. It was a bit of a pain to use a database in\n",
    "that setting since we had to use `sqlalchemy` to translate `pandas`-like\n",
    "commands (`where`, `select`, etc.) into SQL commands that the database\n",
    "understands. Not all `pandas` commands can currently be translated with\n",
    "SQLite databases. For example, we can compute a mean with an SQLite database\n",
    "but can't easily compute a median. So you might be wondering: why should we use\n",
    "databases at all? \n",
    "\n",
    "Databases are beneficial in a large-scale setting:\n",
    "\n",
    "- They enable storing large data sets across multiple computers with backups.\n",
    "- They provide mechanisms for ensuring data integrity and validating input.\n",
    "- They provide security and data access control.\n",
    "- They allow multiple users to access data simultaneously \n",
    "  and remotely without conflicts and errors.\n",
    "  For example, there are billions of Google searches conducted daily in 2021 {cite:p}`googlesearches`. \n",
    "  Can you imagine if Google stored all of the data \n",
    "  from those searches in a single `.csv` file!? Chaos would ensue! \n",
    "\n",
    "## Writing data from Python to a `.csv` file\n",
    "\n",
    "```{index} write function; to_csv, pandas.DataFrame; to_csv\n",
    "```\n",
    "\n",
    "At the middle and end of a data analysis, we often want to write a data frame\n",
    "that has changed (either through filtering, selecting, mutating or summarizing)\n",
    "to a file to share it with others or use it for another step in the analysis.\n",
    "The most straightforward way to do this is to use the `to_csv` function\n",
    "from the `pandas` package.  The default\n",
    "arguments for this file are to use a comma (`,`) as the delimiter and include\n",
    "column names. Below we demonstrate creating a new version of the Canadian\n",
    "languages data set without the official languages category according to the\n",
    "Canadian 2016 Census, and then writing this to a `.csv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c784de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_official_lang_data = canlang_data[canlang_data['category'] != 'Official languages']\n",
    "no_official_lang_data.to_csv(\"data/no_official_languages.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de689f5-03ef-40c5-ab58-30a8de656458",
   "metadata": {},
   "source": [
    "## Obtaining data from the web \n",
    "\n",
    "> **Note:** This section is not required reading for the remainder of the textbook. It\n",
    "> is included for those readers interested in learning a little bit more about\n",
    "> how to obtain different types of data from the web.\n",
    "\n",
    "```{index} see: application programming interface; API\n",
    "```\n",
    "\n",
    "```{index} API\n",
    "```\n",
    "\n",
    "Data doesn't just magically appear on your computer; you need to get it from\n",
    "somewhere. Earlier in the chapter we showed you how to access data stored in a\n",
    "plain text, spreadsheet-like format (e.g., comma- or tab-separated) from a web\n",
    "URL using one of the `read_*` functions from the `pandas`. But as time goes\n",
    "on, it is increasingly uncommon to find data (especially large amounts of data)\n",
    "in this format available for download from a URL. Instead, websites now often\n",
    "offer something known as an **a**pplication **p**rogramming **i**nterface\n",
    "(API), which\n",
    "provides a programmatic way to ask for subsets of a data set. This allows the\n",
    "website owner to control *who* has access to the data, *what portion* of the\n",
    "data they have access to, and *how much* data they can access.  Typically, the\n",
    "website owner will give you a *token* (a secret string of characters somewhat\n",
    "like a password) that you have to provide when accessing the API.\n",
    "\n",
    "```{index} web scraping, CSS, HTML\n",
    "```\n",
    "\n",
    "```{index} see: hypertext markup language; HTML\n",
    "```\n",
    "\n",
    "```{index} see: cascading style sheet; CSS\n",
    "```\n",
    "\n",
    "Another interesting thought: websites themselves *are* data! When you type a\n",
    "URL into your browser window, your browser asks the *web server* (another\n",
    "computer on the internet whose job it is to respond to requests for the\n",
    "website) to give it the website's data, and then your browser translates that\n",
    "data into something you can see. If the website shows you some information that\n",
    "you're interested in, you could *create* a data set for yourself by copying and\n",
    "pasting that information into a file. This process of taking information\n",
    "directly from what a website displays is called \n",
    "*web scraping* (or sometimes *screen scraping*). Now, of course, copying and pasting\n",
    "information manually is a painstaking and error-prone process, especially when\n",
    "there is a lot of information to gather. So instead of asking your browser to\n",
    "translate the information that the web server provides into something you can\n",
    "see, you can collect that data programmatically&mdash;in the form of\n",
    "**h**yper**t**ext **m**arkup **l**anguage \n",
    "(HTML) \n",
    "and **c**ascading **s**tyle **s**heet (CSS) code&mdash;and process it \n",
    "to extract useful information. HTML provides the\n",
    "basic structure of a site and tells the webpage how to display the content\n",
    "(e.g., titles, paragraphs, bullet lists etc.), whereas CSS helps style the\n",
    "content and tells the webpage how the HTML elements should \n",
    "be presented (e.g., colors, layouts, fonts etc.). \n",
    "\n",
    "This subsection will show you the basics of both web scraping\n",
    "with the [`BeautifulSoup` Python package](https://beautiful-soup-4.readthedocs.io/en/latest/) {cite:p}`beautifulsoup`\n",
    "and accessing the Twitter API\n",
    "using the [`tweepy` Python package](https://github.com/tweepy/tweepy) {cite:p}`tweepy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a70710-9bd4-459d-807f-b4d39132a124",
   "metadata": {},
   "source": [
    "### Web scraping\n",
    "\n",
    "#### HTML and CSS selectors\n",
    "\n",
    "```{index} web scraping, HTML; selector, CSS; selector, Craiglist\n",
    "```\n",
    "\n",
    "When you enter a URL into your browser, your browser connects to the\n",
    "web server at that URL and asks for the *source code* for the website.\n",
    "This is the data that the browser translates \n",
    "into something you can see; so if we\n",
    "are going to create our own data by scraping a website, we have to first understand\n",
    "what that data looks like! For example, let's say we are interested\n",
    "in knowing the average rental price (per square foot) of the most recently\n",
    "available one-bedroom apartments in Vancouver \n",
    "on [Craiglist](https://vancouver.craigslist.org). When we visit the Vancouver Craigslist\n",
    "website and search for one-bedroom apartments, \n",
    "we should see something similar to {numref}`fig:craigslist-human`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bcd4e0-4db2-43db-a090-e3182ef88320",
   "metadata": {},
   "source": [
    "```{figure} img/craigslist_human.png\n",
    ":name: fig:craigslist-human\n",
    "\n",
    "Craigslist webpage of advertisements for one-bedroom apartments.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd0f764-501d-4ee7-8ad9-619988c7de28",
   "metadata": {},
   "source": [
    "Based on what our browser shows us, it's pretty easy to find the size and price\n",
    "for each apartment listed. But we would like to be able to obtain that information\n",
    "using Python, without any manual human effort or copying and pasting. We do this by\n",
    "examining the *source code* that the web server actually sent our browser to\n",
    "display for us. We show a snippet of it below; the \n",
    "entire source \n",
    "is [included with the code for this book](https://github.com/UBC-DSCI/introduction-to-datascience-python/blob/main/source/img/website_source.txt):\n",
    "\n",
    "```html\n",
    "        <span class=\"result-meta\">\n",
    "                <span class=\"result-price\">$800</span>\n",
    "\n",
    "                <span class=\"housing\">\n",
    "                    1br -\n",
    "                </span>\n",
    "\n",
    "                <span class=\"result-hood\"> (13768 108th Avenue)</span>\n",
    "\n",
    "                <span class=\"result-tags\">\n",
    "                    <span class=\"maptag\" data-pid=\"6786042973\">map</span>\n",
    "                </span>\n",
    "\n",
    "                <span class=\"banish icon icon-trash\" role=\"button\">\n",
    "                    <span class=\"screen-reader-text\">hide this posting</span>\n",
    "                </span>\n",
    "\n",
    "            <span class=\"unbanish icon icon-trash red\" role=\"button\" aria-hidden\n",
    "            <a href=\"#\" class=\"restore-link\">\n",
    "                <span class=\"restore-narrow-text\">restore</span>\n",
    "                <span class=\"restore-wide-text\">restore this posting</span>\n",
    "            </a>\n",
    "\n",
    "        </span>\n",
    "    </p>\n",
    "</li>\n",
    "         <li class=\"result-row\" data-pid=\"6788463837\">\n",
    "                  \n",
    "        <a href=\"https://vancouver.craigslist.org/nvn/apa/d/north-vancouver-luxu\n",
    "                <span class=\"result-price\">$2285</span>\n",
    "        </a>\n",
    "```\n",
    "\n",
    "Oof...you can tell that the source code for a web page is not really designed\n",
    "for humans to understand easily. However, if you look through it closely, you\n",
    "will find that the information we're interested in is hidden among the muck.\n",
    "For example, near the top of the snippet\n",
    "above you can see a line that looks like\n",
    "\n",
    "```html\n",
    "<span class=\"result-price\">$800</span>\n",
    "```\n",
    "\n",
    "That is definitely storing the price of a particular apartment. With some more\n",
    "investigation, you should be able to find things like the date and time of the\n",
    "listing, the address of the listing, and more. So this source code most likely\n",
    "contains all the information we are interested in!\n",
    "\n",
    "```{index} HTML; tag\n",
    "```\n",
    "\n",
    "Let's dig into that line above a bit more. You can see that\n",
    "that bit of code has an *opening tag* (words between `<` and `>`, like\n",
    "`<span>`) and a *closing tag* (the same with a slash, like `</span>`). HTML\n",
    "source code generally stores its data between opening and closing tags like\n",
    "these. Tags are keywords that tell the web browser how to display or format\n",
    "the content. Above you can see that the information we want (`$800`) is stored\n",
    "between an opening and closing tag (`<span>` and `</span>`). In the opening\n",
    "tag, you can also see a very useful \"class\" (a special word that is sometimes\n",
    "included with opening tags): `class=\"result-price\"`. Since we want R to\n",
    "programmatically sort through all of the source code for the website to find\n",
    "apartment prices, maybe we can look for all the tags with the `\"result-price\"`\n",
    "class, and grab the information between the opening and closing tag. Indeed,\n",
    "take a look at another line of the source snippet above:\n",
    "\n",
    "```html\n",
    "<span class=\"result-price\">$2285</span>\n",
    "```\n",
    "\n",
    "It's yet another price for an apartment listing, and the tags surrounding it\n",
    "have the `\"result-price\"` class. Wonderful! Now that we know what pattern we\n",
    "are looking for&mdash;a dollar amount between opening and closing tags that have the\n",
    "`\"result-price\"` class&mdash;we should be able to use code to pull out all of the \n",
    "matching patterns from the source code to obtain our data. This sort of \"pattern\"\n",
    "is known as a *CSS selector* (where CSS stands for **c**ascading **s**tyle **s**heet).\n",
    "\n",
    "The above was a simple example of \"finding the pattern to look for\"; many \n",
    "websites are quite a bit larger and more complex, and so is their website\n",
    "source code. Fortunately, there are tools available to make this process\n",
    "easier. For example, \n",
    "[SelectorGadget](https://selectorgadget.com/) is \n",
    "an open-source tool that simplifies identifying the generating \n",
    "and finding of CSS selectors. \n",
    "At the end of the chapter in the additional resources section, we include a link to\n",
    "a short video on how to install and use the SelectorGadget tool to \n",
    "obtain CSS selectors for use in web scraping. \n",
    "After installing and enabling the tool, you can click the \n",
    "website element for which you want an appropriate selector. For \n",
    "example, if we click the price of an apartment listing, we\n",
    "find that SelectorGadget shows us the selector `.result-price`\n",
    "in its toolbar, and highlights all the other apartment\n",
    "prices that would be obtained using that selector ({numref}`fig:sg1`).\n",
    "\n",
    "```{figure} img/sg1.png\n",
    ":name: fig:sg1\n",
    "\n",
    "Using the SelectorGadget on a Craigslist webpage to obtain the CCS selector useful for obtaining apartment prices.\n",
    "```\n",
    "\n",
    "If we then click the size of an apartment listing, SelectorGadget shows us\n",
    "the `span` selector, and highlights many of the lines on the page; this indicates that the\n",
    "`span` selector is not specific enough to capture only apartment sizes ({numref}`fig:sg3`). \n",
    "\n",
    "```{figure} img/sg3.png\n",
    ":name: fig:sg3\n",
    "\n",
    "Using the SelectorGadget on a Craigslist webpage to obtain a CCS selector useful for obtaining apartment sizes.\n",
    "```\n",
    "\n",
    "To narrow the selector, we can click one of the highlighted elements that\n",
    "we *do not* want. For example, we can deselect the \"pic/map\" links, \n",
    "resulting in only the data we want highlighted using the `.housing` selector ({numref}`fig:sg2`).\n",
    "\n",
    "```{figure} img/sg2.png\n",
    ":name: fig:sg2\n",
    "\n",
    "Using the SelectorGadget on a Craigslist webpage to refine the CCS selector to one that is most useful for obtaining apartment sizes.\n",
    "```\n",
    "\n",
    "So to scrape information about the square footage and rental price\n",
    "of apartment listings, we need to use\n",
    "the two CSS selectors `.housing` and `.result-price`, respectively.\n",
    "The selector gadget returns them to us as a comma-separated list (here\n",
    "`.housing , .result-price`), which is exactly the format we need to provide to\n",
    "Python if we are using more than one CSS selector.\n",
    "\n",
    "**Stop! Are you allowed to scrape that website?**\n",
    "\n",
    "```{index} web scraping; permission\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a6941f-eebc-4351-a629-2b6356594bc3",
   "metadata": {},
   "source": [
    "*Before* scraping data from the web, you should always check whether or not\n",
    "you are *allowed* to scrape it! There are two documents that are important\n",
    "for this: the `robots.txt` file and the Terms of Service\n",
    "document. If we take a look at [Craigslist's Terms of Service document](https://www.craigslist.org/about/terms.of.use),\n",
    "we find the following text: *\"You agree not to copy/collect CL content \n",
    "via robots, spiders, scripts, scrapers, crawlers, or any automated or manual equivalent (e.g., by hand).\"*\n",
    "So unfortunately, without explicit permission, we are not allowed to scrape the website.\n",
    "\n",
    "```{index} Wikipedia\n",
    "```\n",
    "\n",
    "What to do now? Well, we *could* ask the owner of Craigslist for permission to scrape.\n",
    "However, we are not likely to get a response, and even if we did they would not likely give us permission.\n",
    "The more realistic answer is that we simply cannot scrape Craigslist. If we still want\n",
    "to find data about rental prices in Vancouver, we must go elsewhere.\n",
    "To continue learning how to scrape data from the web, let's instead\n",
    "scrape data on the population of Canadian cities from Wikipedia.\n",
    "We have checked the [Terms of Service document](https://foundation.wikimedia.org/wiki/Terms_of_Use/en),\n",
    "and it does not mention that web scraping is disallowed. \n",
    "We will use the SelectorGadget tool to pick elements that we are interested in\n",
    "(city names and population counts) and deselect others to indicate that we are not \n",
    "interested in them (province names), as shown in {numref}`fig:sg4`.\n",
    "\n",
    "```{figure} img/selectorgadget-wiki-updated.png\n",
    ":name: fig:sg4\n",
    "\n",
    "Using the SelectorGadget on a Wikipedia webpage.\n",
    "```\n",
    "\n",
    "We include a link to a short video tutorial on this process at the end of the chapter\n",
    "in the additional resources section. SelectorGadget provides in its toolbar\n",
    "the following list of CSS selectors to use:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe21446-b745-4dfe-bddd-f24620d5202b",
   "metadata": {},
   "source": [
    "```\n",
    "td:nth-child(8) , \n",
    "td:nth-child(6) , \n",
    "td:nth-child(4) , \n",
    ".mw-parser-output div tr+ tr td:nth-child(2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7268c5-233d-41b5-b2bd-5b8d1e19aba5",
   "metadata": {},
   "source": [
    "Now that we have the CSS selectors that describe the properties of the elements\n",
    "that we want to target (e.g., has a tag name `price`), we can use them to find\n",
    "certain elements in web pages and extract data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a8e59-5fa4-464c-a91c-9c8e6a0da493",
   "metadata": {},
   "source": [
    "**Using `BeautifulSoup`**\n",
    "\n",
    "```{index} BeautifulSoup, requests\n",
    "```\n",
    "\n",
    "Now that we have our CSS selectors we can use the `requests` and `BeautifulSoup` Python packages to scrape our desired data from the website. We start by loading the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72bbc648-cdc4-480d-81e8-1cc0571f5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a099631-b07b-4f8c-bbb0-7ad8fdb997ba",
   "metadata": {},
   "source": [
    "Next, we tell Python what page we want to scrape by providing the webpage's URL in quotations to the function `requests.get` and pass it into the `BeautifulSoup` function for parsing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14e0b1e2-788f-4126-a4ae-9f49baf4c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = requests.get(\"https://en.wikipedia.org/wiki/Canada\")\n",
    "page = BeautifulSoup(wiki.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c1b4a8-05b4-4e95-a1f8-3ce84c3ea48b",
   "metadata": {},
   "source": [
    "The `requests.get` function sends a `GET` request to the specified URL and returns the server's response to the HTTP request (*i.e.* a `requests.Response` object). The `BeautifulSoup` function takes the content of the response and returns the HTML source code itself, which we have\n",
    "stored in the `page` variable. Next, we use the `select` method of the page object along with the CSS selectors we obtained from the SelectorGadget tool. Make sure to surround the selectors with quotation marks; `select` expects that\n",
    "argument is a string. It selects *nodes* from the HTML document that \n",
    "match the CSS selectors you specified. A *node* is an HTML tag pair (e.g.,\n",
    "`<td>` and `</td>` which defines the cell of a table) combined with the content\n",
    "stored between the tags. For our CSS selector `td:nth-child(6)`, an example\n",
    "node that would be selected would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab4c7db-ae5d-4a07-b53f-d31817874357",
   "metadata": {},
   "source": [
    "```\n",
    "<td style=\"text-align:left;background:#f0f0f0;\">\n",
    "<a href=\"/wiki/London,_Ontario\" title=\"London, Ontario\">London</a>\n",
    "</td>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c816b33-e425-47ed-8115-ba2868a12330",
   "metadata": {},
   "source": [
    "We store the result of the `select` function in the `population_nodes` variable. Note that it returns a list, and we slice the list to only print the first 5 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e44eed49-8de7-4e4c-9843-4a5eace75b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td style=\"text-align:left;\"><a href=\"/wiki/Greater_Toronto_Area\" title=\"Greater Toronto Area\">Toronto</a></td>,\n",
       " <td style=\"text-align:right;\">6,202,225</td>,\n",
       " <td style=\"text-align:left;\"><a href=\"/wiki/London,_Ontario\" title=\"London, Ontario\">London</a></td>,\n",
       " <td style=\"text-align:right;\">543,551\n",
       " </td>,\n",
       " <td style=\"text-align:left;\"><a href=\"/wiki/Greater_Montreal\" title=\"Greater Montreal\">Montreal</a></td>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_nodes = page.select(\n",
    "    \"td:nth-child(8) , td:nth-child(6) , td:nth-child(4) , .mw-parser-output div td:nth-child(2)\"\n",
    ")\n",
    "population_nodes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27081e47-e63f-446a-9366-262fa63f8468",
   "metadata": {},
   "source": [
    "Next we extract the meaningful data&mdash;in other words, we get rid of the HTML code syntax and tags&mdash;from \n",
    "the nodes using the `get_text`\n",
    "function. In the case of the example\n",
    "node above, `get_text` function returns `\"London\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ca4a2a5-f8c4-45f8-a2e0-6c36a40eb7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toronto', '6,202,225', 'London', '543,551\\n', 'Montreal']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row.get_text() for row in population_nodes][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b4caa-ff60-4518-9773-f6eae90c87cc",
   "metadata": {},
   "source": [
    "Fantastic! We seem to have extracted the data of interest from the \n",
    "raw HTML source code. But we are not quite done; the data\n",
    "is not yet in an optimal format for data analysis. Both the city names and\n",
    "population are encoded as characters in a single vector, instead of being in a\n",
    "data frame with one character column for city and one numeric column for\n",
    "population (like a spreadsheet).\n",
    "Additionally, the populations contain commas (not useful for programmatically\n",
    "dealing with numbers), and some even contain a line break character at the end\n",
    "(`\\n`). In Chapter {ref}`wrangling`, we will learn more about how to *wrangle* data\n",
    "such as this into a more useful format for data analysis using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44734239-9f13-4731-91fd-75171a6af252",
   "metadata": {},
   "source": [
    "### Using an API\n",
    "\n",
    "```{index} API\n",
    "```\n",
    "\n",
    "Rather than posting a data file at a URL for you to download, many websites these days\n",
    "provide an API that must be accessed through a programming language like Python. The benefit of this\n",
    "is that data owners have much more control over the data they provide to users. However, unlike\n",
    "web scraping, there is no consistent way to access an API across websites. Every website typically\n",
    "has its own API designed especially for its own use case. Therefore we will just provide one example\n",
    "of accessing data through an API in this book, with the hope that it gives you enough of a basic\n",
    "idea that you can learn how to use another API if needed.\n",
    "\n",
    "```{index} API; tweepy, tweepy, Twitter, API; token\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7397a1-bada-42c3-850b-66816436c68b",
   "metadata": {},
   "source": [
    "In particular, in this book we will show you the basics of how to use\n",
    "the `tweepy` package in Python to access\n",
    "data from the Twitter API. `tweepy` requires the [Twitter Developer Portal](https://developer.twitter.com/en/portal/dashboard) and you will need to get tokens and secrets from that, through which your access to the data will then be authenticated and controlled.\n",
    "\n",
    "Once you get the access keys and tokens, you can store it in the `config.ini` file. Then you can follow along with the examples that we show here.\n",
    "To get started, load the `tweepy` package and authenticate our access to the Twitter developer portal account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a175e1ba-6bcc-4f39-b10a-9c13505d1b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Authentication\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "api_key = config['twitter'][\"api_key\"]\n",
    "api_key_secret = config['twitter'][\"api_key_secret\"]\n",
    "access_token = config['twitter'][\"access_token\"]\n",
    "access_token_secret = config['twitter'][\"access_token_secret\"]\n",
    " \n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    " \n",
    "api = tweepy.API(auth)\n",
    "\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print('Successful Authentication')\n",
    "except:\n",
    "    print('Failed authentication')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d8a8e-57df-4376-ac82-ac8ca79ecf16",
   "metadata": {},
   "source": [
    "`tweepy` provides an extensive set of functions to search \n",
    "Twitter for tweets, users, their followers, and more. \n",
    "Let's construct a small data set of the last 200 tweets and \n",
    "retweets from the [@scikit_learn](https://twitter.com/scikit_learn) account. A few of the most recent tweets\n",
    "are shown in {numref}`fig:01-scikit-learn-twitter`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9461900d-7ba9-4798-9847-de360a37f60b",
   "metadata": {},
   "source": [
    "```{figure} img/scikit-learn-twitter.png\n",
    ":name: fig:01-scikit-learn-twitter\n",
    "\n",
    "The `scikit-learn` account Twitter feed.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f6987-51b3-4e46-87e6-29b365425164",
   "metadata": {},
   "source": [
    "**Stop! Think about your API usage carefully!**\n",
    "\n",
    "When you access an API, you are initiating a transfer of data from a web server\n",
    "to your computer. Web servers are expensive to run and do not have infinite resources.\n",
    "If you try to ask for *too much data* at once, you can use up a huge amount of the server's bandwidth. \n",
    "If you try to ask for data *too frequently*&mdash;e.g., if you \n",
    "make many requests to the server in quick succession&mdash;you can also bog the server down and make\n",
    "it unable to talk to anyone else. Most servers have mechanisms to revoke your access if you are not\n",
    "careful, but you should try to prevent issues from happening in the first place by being extra careful\n",
    "with how you write and run your code. You should also keep in mind that when a website owner\n",
    "grants you API access, they also usually specify a limit (or *quota*) of how much data you can ask for.\n",
    "Be careful not to overrun your quota! In this example, we should take a look at\n",
    " [the Twitter website](https://developer.twitter.com/en/docs/twitter-api/rate-limits) to see what limits\n",
    "we should abide by when using the API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caaa911-aea9-4f3e-a713-8b1ae3c01e9e",
   "metadata": {},
   "source": [
    "**Using `tweepy`**\n",
    "\n",
    "After checking the Twitter website, it seems like asking for 200 tweets one time is acceptable.\n",
    "So we can use the `user_timeline` function to ask for the last 200 tweets from the [@scikit_learn](https://twitter.com/scikit_learn) account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ea3f90d-cc28-4739-9e45-2d84126a6420",
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = \"scikit_learn\"\n",
    "\n",
    "scikit_learn_tweets = api.user_timeline(\n",
    "    screen_name=userID,\n",
    "    count=200,\n",
    "    include_rts=True,\n",
    "    tweet_mode=\"extended\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33295844-153a-48c1-aaa5-633cae4683c6",
   "metadata": {},
   "source": [
    "Let's take a look at the first 3 most recent tweets of [@scikit_learn](https://twitter.com/scikit_learn) through accessing the attributes of tweet data dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91da6e20-0d04-4d4d-94f1-4a89498382cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1555686128971403265\n",
      "2022-08-05 22:44:11+00:00\n",
      "scikit-learn 1.1.2 is out on https://t.co/lSpi4eDc2t and conda-forge!\n",
      "\n",
      "This is a small maintenance release that fixes a couple of regressions:\n",
      "https://t.co/Oa84ES0qpG\n",
      "\n",
      "\n",
      "ID: 1549321048943988737\n",
      "2022-07-19 09:11:37+00:00\n",
      "RT @MarenWestermann: @scikit_learn It is worth highlighting that this scikit-learn sprint is seeing the highest participation of women out…\n",
      "\n",
      "\n",
      "ID: 1548339716465930244\n",
      "2022-07-16 16:12:09+00:00\n",
      "@StefanieMolin @theBodlina @RichardKlima We continue pulling requests here in Dublin. Putting some Made in Ireland code in the scikit-learn codebase 🇮🇪 . Current stats: 18 PRs opened, 12 merged 🚀 https://t.co/ccWy8vh8YI\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for info in scikit_learn_tweets[:3]:\n",
    "    print(\"ID: {}\".format(info.id))\n",
    "    print(info.created_at)\n",
    "    print(info.full_text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f82204-0c3a-44f5-a138-b922b1becdd7",
   "metadata": {},
   "source": [
    "A full list of available attributes provided by Twitter API can be found [here](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c9ee1-518a-4a92-9054-cc40ee661aca",
   "metadata": {},
   "source": [
    "For the demonstration purpose, let's only use a\n",
    "few variables of interest: `created_at`,  `user.screen_name`, `retweeted`,\n",
    "and `full_text`, and construct a `pandas` DataFrame using the extracted information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9726b9f7-2aaa-4400-b07c-59dfa709e35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>user</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-05 22:44:11+00:00</td>\n",
       "      <td>scikit_learn</td>\n",
       "      <td>True</td>\n",
       "      <td>scikit-learn 1.1.2 is out on https://t.co/lSpi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-19 09:11:37+00:00</td>\n",
       "      <td>scikit_learn</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @MarenWestermann: @scikit_learn It is worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-16 16:12:09+00:00</td>\n",
       "      <td>scikit_learn</td>\n",
       "      <td>False</td>\n",
       "      <td>@StefanieMolin @theBodlina @RichardKlima We co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-16 11:37:46+00:00</td>\n",
       "      <td>scikit_learn</td>\n",
       "      <td>False</td>\n",
       "      <td>This is their first contribution to @scikit_le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-16 11:33:40+00:00</td>\n",
       "      <td>scikit_learn</td>\n",
       "      <td>False</td>\n",
       "      <td>Feel free to interact with us on our Discord c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2019-01-28 21:04:23+00:00</td>\n",
       "      <td>scikit_learn</td>\n",
       "      <td>False</td>\n",
       "      <td>[scikit-learn] https://t.co/g02ZFpcjQo johayon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2019-01-28 21:04:23+00:00</td>\n",
       "      <td>scikit_learn</td>\n",
       "      <td>False</td>\n",
       "      <td>[scikit-learn] https://t.co/JQZeJuovhN johayon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2019-01-28 21:04:23+00:00</td>\n",
       "      <td>scikit_learn</td>\n",
       "      <td>False</td>\n",
       "      <td>[scikit-learn] https://t.co/ea7pDyQh4v johayon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2019-01-28 21:04:23+00:00</td>\n",
       "      <td>scikit_learn</td>\n",
       "      <td>False</td>\n",
       "      <td>[scikit-learn] https://t.co/AyecUAk5xD johayon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2019-01-28 21:04:22+00:00</td>\n",
       "      <td>scikit_learn</td>\n",
       "      <td>False</td>\n",
       "      <td>[scikit-learn] https://t.co/mADHQ5syef johayon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time          user  is_retweet  \\\n",
       "0   2022-08-05 22:44:11+00:00  scikit_learn        True   \n",
       "1   2022-07-19 09:11:37+00:00  scikit_learn       False   \n",
       "2   2022-07-16 16:12:09+00:00  scikit_learn       False   \n",
       "3   2022-07-16 11:37:46+00:00  scikit_learn       False   \n",
       "4   2022-07-16 11:33:40+00:00  scikit_learn       False   \n",
       "..                        ...           ...         ...   \n",
       "195 2019-01-28 21:04:23+00:00  scikit_learn       False   \n",
       "196 2019-01-28 21:04:23+00:00  scikit_learn       False   \n",
       "197 2019-01-28 21:04:23+00:00  scikit_learn       False   \n",
       "198 2019-01-28 21:04:23+00:00  scikit_learn       False   \n",
       "199 2019-01-28 21:04:22+00:00  scikit_learn       False   \n",
       "\n",
       "                                                  text  \n",
       "0    scikit-learn 1.1.2 is out on https://t.co/lSpi...  \n",
       "1    RT @MarenWestermann: @scikit_learn It is worth...  \n",
       "2    @StefanieMolin @theBodlina @RichardKlima We co...  \n",
       "3    This is their first contribution to @scikit_le...  \n",
       "4    Feel free to interact with us on our Discord c...  \n",
       "..                                                 ...  \n",
       "195  [scikit-learn] https://t.co/g02ZFpcjQo johayon...  \n",
       "196  [scikit-learn] https://t.co/JQZeJuovhN johayon...  \n",
       "197  [scikit-learn] https://t.co/ea7pDyQh4v johayon...  \n",
       "198  [scikit-learn] https://t.co/AyecUAk5xD johayon...  \n",
       "199  [scikit-learn] https://t.co/mADHQ5syef johayon...  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"time\", \"user\", \"is_retweet\", \"text\"]\n",
    "data = []\n",
    "for tweet in scikit_learn_tweets:\n",
    "    data.append([tweet.created_at, tweet.user.screen_name, tweet.retweeted, tweet.full_text])\n",
    "    \n",
    "scikit_learn_tweets_df = pd.DataFrame(data, columns=columns)\n",
    "scikit_learn_tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa518b6-5c72-43f8-b5be-584b0f6196a7",
   "metadata": {},
   "source": [
    "If you look back up at the image of the [@scikit_learn](https://twitter.com/scikit_learn) Twitter page, you will\n",
    "recognize the text of the most recent few tweets in the above data frame.  In\n",
    "other words, we have successfully created a small data set using the Twitter\n",
    "API&mdash;neat! This data is also quite different from what we obtained from web scraping;\n",
    "the extracted information can be easily converted into a `pandas` data frame (although not *every* API will provide data in such a nice format).\n",
    "From this point onward, the `scikit_learn_tweets_df` data frame is stored on your\n",
    "machine, and you can play with it to your heart's content. For example, you can use\n",
    "`pandas.to_csv` to save it to a file and `pandas.read_csv` to read it into Python again later; \n",
    "and after reading the next few chapters you will have the skills to\n",
    "compute the percentage of retweets versus tweets, find the most oft-retweeted\n",
    "account, make visualizations of the data, and much more! If you decide that you want \n",
    "to ask the Twitter API for more data \n",
    "(see [the `tweepy` page](https://github.com/tweepy/tweepy)\n",
    "for more examples of what is possible), just be mindful as usual about how much\n",
    "data you are requesting and how frequently you are making requests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73a74ad",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Practice exercises for the material covered in this chapter \n",
    "can be found in the accompanying \n",
    "[worksheets repository](https://github.com/UBC-DSCI/data-science-a-first-intro-worksheets#readme)\n",
    "in the \"Reading in data locally and from the web\" row.\n",
    "You can launch an interactive version of the worksheet in your browser by clicking the \"launch binder\" button.\n",
    "You can also preview a non-interactive version of the worksheet by clicking \"view worksheet.\"\n",
    "If you instead decide to download the worksheet and run it on your own machine,\n",
    "make sure to follow the instructions for computer setup\n",
    "found in Chapter {ref}`move-to-your-own-machine`. This will ensure that the automated feedback\n",
    "and guidance that the worksheets provide will function as intended.\n",
    "\n",
    "## Additional resources\n",
    "\n",
    "- The [`pandas` documentation](https://pandas.pydata.org/docs/getting_started/index.html) \n",
    "  provides the documentation for many of the reading functions we cover in this chapter.\n",
    "  It is where you should look if you want to learn more about the functions in this\n",
    "  chapter, the full set of arguments you can use, and other related functions.\n",
    "  The site also provides a very nice cheat sheet that summarizes many of the data\n",
    "  wrangling functions from this chapter.\n",
    "- Sometimes you might run into data in such poor shape that none of the reading\n",
    "  functions we cover in this chapter work. In that case, you can consult the\n",
    "  [data loading chapter](https://wesmckinney.com/book/accessing-data.html#io_flat_files) from *Python for Data Analysis* {cite:p}`mckinney2012python`, which goes into a lot more detail about how Python parses\n",
    "  text from files into data frames.\n",
    "- A [video](https://www.youtube.com/embed/ephId3mYu9o) from the Udacity\n",
    "  course *Linux Command Line Basics* provides a good explanation of absolute versus relative paths.\n",
    "- If you read the subsection on obtaining data from the web via scraping and\n",
    "  APIs, we provide two companion tutorial video links for how to use the\n",
    "  SelectorGadget tool to obtain desired CSS selectors for:\n",
    "    - [extracting the data for apartment listings on Craigslist](https://www.youtube.com/embed/YdIWI6K64zo), and\n",
    "    - [extracting Canadian city names and 2016 populations from Wikipedia](https://www.youtube.com/embed/O9HKbdhqYzk).\n",
    "- The [`polite` R package](https://dmi3kno.github.io/polite/) {cite:p}`polite` provides\n",
    "  a set of tools for responsibly scraping data from websites.\n",
    "\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4fef4",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "py:percent,md:myst,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
